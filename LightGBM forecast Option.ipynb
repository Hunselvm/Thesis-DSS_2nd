{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e9b7fe",
   "metadata": {},
   "source": [
    "LightGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fa0f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded test_data_h1: (2571058, 176)\n",
      "Columns: ['ID', 'iv_cw', 'date', 'cp_flag', 'option_price', 'stock_price', 'moneyness', 'time_to_expiry', 'strike_price', 'volume']...\n",
      "--------------------------------------------------\n",
      "Loaded test_data_h5: (2203398, 176)\n",
      "Columns: ['ID', 'iv_cw', 'date', 'cp_flag', 'option_price', 'stock_price', 'moneyness', 'time_to_expiry', 'strike_price', 'volume']...\n",
      "--------------------------------------------------\n",
      "Loaded test_data_h21: (1341910, 176)\n",
      "Columns: ['ID', 'iv_cw', 'date', 'cp_flag', 'option_price', 'stock_price', 'moneyness', 'time_to_expiry', 'strike_price', 'volume']...\n",
      "--------------------------------------------------\n",
      "\n",
      "Option-only data for horizon 1:\n",
      "Shape: (2571058, 17)\n",
      "   cp_flag  stock_price  moneyness  time_to_expiry  strike_price      rf  \\\n",
      "0        1      115.545   0.996078              23         116.0  0.0245   \n",
      "1        1      115.545   0.987564              23         117.0  0.0245   \n",
      "2        1      115.545   0.979195              23         118.0  0.0245   \n",
      "3        1      115.545   0.970966              23         119.0  0.0245   \n",
      "4        1      115.545   0.962875              23         120.0  0.0245   \n",
      "\n",
      "      delta     gamma       vega     theta   iv_ahbs  iv_ahbs_error     iv_bs  \\\n",
      "0  0.513613  0.061929  11.852320 -18.68445  0.299345      -0.098264  0.288808   \n",
      "1  0.451355  0.062008  11.773890 -18.46989  0.298947      -0.102526  0.288808   \n",
      "2  0.389354  0.060745  11.405690 -17.73958  0.298851      -0.107589  0.288808   \n",
      "3  0.329402  0.057909  10.772000 -16.61241  0.299042      -0.110209  0.288808   \n",
      "4  0.273000  0.053728   9.892975 -15.15339  0.299507      -0.110953  0.288808   \n",
      "\n",
      "   iv_bs_error     iv_cw  iv_cw_error  impl_volatility  \n",
      "0    -0.087727  0.264812    -0.063731         0.201081  \n",
      "1    -0.092387  0.266365    -0.069944         0.196421  \n",
      "2    -0.097546  0.269537    -0.078275         0.191262  \n",
      "3    -0.099975  0.274232    -0.085399         0.188833  \n",
      "4    -0.100254  0.280334    -0.091780         0.188554  \n",
      "--------------------------------------------------\n",
      "\n",
      "Option-only data for horizon 5:\n",
      "Shape: (2203398, 17)\n",
      "   cp_flag  stock_price  moneyness  time_to_expiry  strike_price      rf  \\\n",
      "0        1      115.545   0.996078              26         116.0  0.0245   \n",
      "1        1      115.545   0.987564              26         117.0  0.0245   \n",
      "2        1      115.545   0.979195              26         118.0  0.0245   \n",
      "3        1      115.545   0.970966              26         119.0  0.0245   \n",
      "4        1      115.545   0.962875              26         120.0  0.0245   \n",
      "\n",
      "      delta     gamma      vega     theta   iv_ahbs  iv_ahbs_error     iv_bs  \\\n",
      "0  0.523424  0.051164  13.45026 -18.46840  0.296150      -0.049271  0.288808   \n",
      "1  0.471456  0.051946  13.35782 -18.30862  0.295814      -0.051901  0.288808   \n",
      "2  0.420004  0.051298  13.32532 -17.79568  0.295779      -0.056310  0.288808   \n",
      "3  0.369470  0.049878  12.74789 -16.96248  0.296031      -0.059309  0.288808   \n",
      "4  0.320101  0.047765  11.71450 -16.05628  0.296556      -0.060488  0.288808   \n",
      "\n",
      "   iv_bs_error     iv_cw  iv_cw_error  impl_volatility  \n",
      "0    -0.041929  0.263030    -0.016151         0.246879  \n",
      "1    -0.044895  0.264520    -0.020607         0.243913  \n",
      "2    -0.049339  0.267565    -0.028096         0.239469  \n",
      "3    -0.052086  0.272075    -0.035353         0.236722  \n",
      "4    -0.052740  0.277940    -0.041872         0.236068  \n",
      "--------------------------------------------------\n",
      "\n",
      "Option-only data for horizon 21:\n",
      "Shape: (1341910, 17)\n",
      "   cp_flag  stock_price  moneyness  time_to_expiry  strike_price      rf  \\\n",
      "0        1      115.545   0.962875              52         120.0  0.0245   \n",
      "1        1      115.545   0.924360              52         125.0  0.0245   \n",
      "2        1      115.545   0.888808              52         130.0  0.0245   \n",
      "3        1      115.545   0.855889              52         135.0  0.0245   \n",
      "4        0      115.545   1.155450              52         100.0  0.0245   \n",
      "\n",
      "      delta     gamma       vega      theta   iv_ahbs  iv_ahbs_error  \\\n",
      "0  0.358767  0.035970  19.286400 -10.090140  0.274520      -0.114858   \n",
      "1  0.200163  0.027383  14.508140  -7.243612  0.283228      -0.129467   \n",
      "2  0.099280  0.017001   9.050467  -4.493535  0.296779      -0.150494   \n",
      "3  0.047403  0.009395   5.130530  -2.602480  0.314044      -0.168159   \n",
      "4 -0.093574  0.012462   8.672492  -5.567660  0.324136       0.005032   \n",
      "\n",
      "      iv_bs  iv_bs_error     iv_cw  iv_cw_error  impl_volatility  \n",
      "0  0.288808    -0.129146  0.261731    -0.102069         0.159662  \n",
      "1  0.288808    -0.135047  0.294981    -0.141220         0.153761  \n",
      "2  0.288808    -0.142523  0.342147    -0.195862         0.146285  \n",
      "3  0.288808    -0.142923  0.396596    -0.250711         0.145885  \n",
      "4  0.288808     0.040360  0.380884    -0.051716         0.329168  \n",
      "--------------------------------------------------\n",
      "\n",
      "Train data:\n",
      "Shape: (2669654, 17)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a dictionary to store data for each horizon\n",
    "test_data = {}\n",
    "horizons = [1, 5, 21]\n",
    "\n",
    "# Load test data for each horizon\n",
    "for horizon in horizons:\n",
    "    # Define the file path\n",
    "    file_path = f'C:/Users/maxva/OneDrive - Tilburg University/Msc. Data Science/Master Thesis/Data/merged_results_h{horizon}.csv'\n",
    "    \n",
    "    # Load the data and store it in the dictionary\n",
    "    test_data[horizon] = pd.read_csv(file_path)\n",
    "    \n",
    "    # Print confirmation and info about the loaded data\n",
    "    print(f\"Loaded test_data_h{horizon}: {test_data[horizon].shape}\")\n",
    "    print(f\"Columns: {test_data[horizon].columns.tolist()[:10]}...\")  # First 10 columns\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Extract option-only features for each horizon\n",
    "option_columns = [\n",
    "    'cp_flag',\n",
    "    'stock_price',\n",
    "    'moneyness',\n",
    "    'time_to_expiry',\n",
    "    'strike_price',\n",
    "    'rf',\n",
    "    'delta',\n",
    "    'gamma',\n",
    "    'vega',\n",
    "    'theta',\n",
    "    'iv_ahbs',\n",
    "    'iv_ahbs_error',\n",
    "    'iv_bs',\n",
    "    'iv_bs_error',\n",
    "    'iv_cw',\n",
    "    'iv_cw_error',\n",
    "    'impl_volatility'\n",
    "]\n",
    "\n",
    "# Create option-only datasets for each horizon\n",
    "option_only_data = {}\n",
    "for horizon in horizons:\n",
    "    option_only_data[horizon] = test_data[horizon][option_columns].copy()\n",
    "    print(f\"\\nOption-only data for horizon {horizon}:\")\n",
    "    print(f\"Shape: {option_only_data[horizon].shape}\")\n",
    "    print(option_only_data[horizon].head())\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "train_data = pd.read_csv('C:/Users/maxva/OneDrive - Tilburg University/Msc. Data Science/Master Thesis/Data/merged_results_train.csv')\n",
    "# Drop the date column\n",
    "train_data = train_data.drop(columns=['date', 'moneyness_category'])\n",
    "train_data = train_data[option_columns]\n",
    "print(f\"\\nTrain data:\")\n",
    "print(f\"Shape: {train_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d70c24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# PART 1: LIGHTGBM MODEL DEFINITION\n",
    "###########################################\n",
    "\n",
    "def create_lgb_model(model_type):\n",
    "\n",
    "    if model_type == 'LGB1':\n",
    "        # Standard LightGBM configuration\n",
    "        params = {\n",
    "            'objective': 'regression',\n",
    "            'metric': 'mse',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': -1\n",
    "        }\n",
    "    \n",
    "    elif model_type == 'LGB2':\n",
    "        # More complex LightGBM configuration with different hyperparameters\n",
    "        params = {\n",
    "            'objective': 'regression',\n",
    "            'metric': 'mse',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 63,\n",
    "            'learning_rate': 0.01,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.7,\n",
    "            'bagging_freq': 4,\n",
    "            'min_data_in_leaf': 20,\n",
    "            'max_depth': 10,\n",
    "            'verbose': -1\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type. Choose from 'LGB1' or 'LGB2'.\")\n",
    "    \n",
    "    return params\n",
    "\n",
    "def train_and_evaluate_model(params, X_train, y_train, X_test, y_test, num_boost_round=100):\n",
    "\n",
    "    # Create LightGBM datasets\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "    \n",
    "    # Train model with early stopping\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=num_boost_round,\n",
    "        valid_sets=[valid_data],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=20, verbose=True)]\n",
    "    )\n",
    "    \n",
    "    # Evaluate model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    return model, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66054835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(option_only, save_paths=True):\n",
    "\n",
    "    features = [\n",
    "    'cp_flag',\n",
    "    'stock_price',\n",
    "    'moneyness',\n",
    "    'time_to_expiry',\n",
    "    'strike_price',\n",
    "    'rf',\n",
    "    'delta',\n",
    "    'gamma',\n",
    "    'vega',\n",
    "    'theta'\n",
    "    ]\n",
    "\n",
    "    X_train = option_only[features]\n",
    "    y_train = {\n",
    "        'bs': option_only['iv_bs_error'],\n",
    "        'ahbs': option_only['iv_ahbs_error'],\n",
    "        'cw': option_only['iv_cw_error']\n",
    "    }\n",
    "\n",
    "    # 3) Scale training data\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train_scaled = pd.DataFrame(\n",
    "        scaler.transform(X_train),\n",
    "        columns=features\n",
    "    )\n",
    "\n",
    "    # 4) Persist artifacts if required\n",
    "    if save_paths:\n",
    "        joblib.dump(scaler, 'scaler.pkl')\n",
    "        joblib.dump(features, 'feature_columns.pkl')\n",
    "\n",
    "    return X_train_scaled, y_train, scaler, features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a205ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# PART 3: PREDICTION FUNCTION\n",
    "###########################################\n",
    "\n",
    "def predict_and_add_to_test_data(models, test_data, scaler, feature_columns, error_type):\n",
    "\n",
    "    # Create a copy of the test data to avoid modifying the original\n",
    "    result_df = test_data.copy()\n",
    "    \n",
    "    # Extract features from test data\n",
    "    X_test = test_data[feature_columns]\n",
    "    \n",
    "    # Scale the features using the pre-fitted scaler\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Original value column name\n",
    "    original_column = f'iv_{error_type}'\n",
    "    \n",
    "    # Generate predictions for each model\n",
    "    for model_name, model in models.items():\n",
    "        # Make predictions\n",
    "        predictions = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Add predictions to the dataframe\n",
    "        column_name = f'iv_{error_type}_pred_{model_name}'\n",
    "        result_df[column_name] = predictions\n",
    "        \n",
    "        # Calculate corrected value by adding the error prediction to the original value\n",
    "        result_df[f'iv_{error_type}_corrected_{model_name}'] = result_df[original_column] + predictions\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5954eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# PART 4: FEATURE IMPORTANCE ANALYSIS\n",
    "###########################################\n",
    "\n",
    "def analyze_feature_importance(model, feature_columns):\n",
    "\n",
    "    # Get feature importance\n",
    "    importance = model.feature_importance(importance_type='split')\n",
    "    \n",
    "    # Create a DataFrame for better visualization\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_columns,\n",
    "        'Importance': importance\n",
    "    })\n",
    "    \n",
    "    # Sort by importance\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    return importance_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefb6278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training models for bs error correction ===\n",
      "\n",
      "Training LGB1_bs...\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.00172862\n",
      "LGB1_bs Test MSE: 0.0017286236568953828\n",
      "\n",
      "Training LGB2_bs...\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.00241189\n",
      "LGB2_bs Test MSE: 0.0024118863476163123\n",
      "\n",
      "=== Training models for ahbs error correction ===\n",
      "\n",
      "Training LGB1_ahbs...\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.00160337\n",
      "LGB1_ahbs Test MSE: 0.0016033746157781438\n",
      "\n",
      "Training LGB2_ahbs...\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.00218432\n",
      "LGB2_ahbs Test MSE: 0.002184317709766686\n",
      "\n",
      "=== Training models for cw error correction ===\n",
      "\n",
      "Training LGB1_cw...\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.00151604\n",
      "LGB1_cw Test MSE: 0.001516035531977813\n",
      "\n",
      "Training LGB2_cw...\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.00202884\n",
      "LGB2_cw Test MSE: 0.0020288352530866698\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###########################################\n",
    "# PART 5: COMPLETE WORKFLOW\n",
    "###########################################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Load data\n",
    "    # Assuming option_only and test_data_h1 are loaded from CSV\n",
    "    # option_only = pd.read_csv('option_data.csv')\n",
    "    # test_data_h1 = pd.read_csv('test_data_h1.csv')\n",
    "    \n",
    "    # Step 2: Prepare data\n",
    "    X_train_scaled, X_test_scaled, y_train_dict, y_test_dict, scaler, feature_columns = prepare_data(train_data)\n",
    "    \n",
    "    # Step 3: Train models for each target variable\n",
    "    models = {}\n",
    "    results = {}\n",
    "    \n",
    "    # Dictionary to store all models\n",
    "    all_models = {\n",
    "        'bs': {},\n",
    "        'ahbs': {},\n",
    "        'cw': {}\n",
    "    }\n",
    "    \n",
    "    # Train models for each error type\n",
    "    for error_type in ['bs', 'ahbs', 'cw']:\n",
    "        print(f\"\\n=== Training models for {error_type} error correction ===\")\n",
    "        \n",
    "        # Get the appropriate training and test targets\n",
    "        y_train = y_train_dict[error_type]\n",
    "        y_test = y_test_dict[error_type]\n",
    "        \n",
    "        # Train each model configuration\n",
    "        for lgb_type in ['LGB1', 'LGB2']:\n",
    "            model_name = f\"{lgb_type}_{error_type}\"\n",
    "            print(f\"\\nTraining {model_name}...\")\n",
    "            \n",
    "            # Create model parameters\n",
    "            params = create_lgb_model(lgb_type)  \n",
    "            \n",
    "            # Train and evaluate model\n",
    "            model, mse = train_and_evaluate_model(\n",
    "                params, X_train_scaled, y_train, X_test_scaled, y_test, num_boost_round=500\n",
    "            )\n",
    "            \n",
    "            # Store model and results\n",
    "            all_models[error_type][lgb_type] = model\n",
    "            results[model_name] = {\n",
    "                'mse': mse,\n",
    "                'feature_importance': analyze_feature_importance(model, feature_columns)\n",
    "            }\n",
    "            \n",
    "            print(f\"{model_name} Test MSE: {mse}\")\n",
    "            \n",
    "            # Save feature importance\n",
    "            results[model_name]['feature_importance'].to_csv(f\"{model_name}_feature_importance.csv\", index=False)\n",
    "            \n",
    "            # Save model (using LightGBM's save_model method)\n",
    "            model.save_model(f\"{model_name}_model.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "762279bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bs LGB1...\n",
      "✓ Model loaded successfully\n",
      "Loading bs LGB2...\n",
      "✓ Model loaded successfully\n",
      "Loading ahbs LGB1...\n",
      "✓ Model loaded successfully\n",
      "Loading ahbs LGB2...\n",
      "✓ Model loaded successfully\n",
      "Loading cw LGB1...\n",
      "✓ Model loaded successfully\n",
      "Loading cw LGB2...\n",
      "✓ Model loaded successfully\n",
      "\n",
      "=== Model Loading Summary ===\n",
      "bs LGB1: ✓ Loaded\n",
      "bs LGB2: ✓ Loaded\n",
      "ahbs LGB1: ✓ Loaded\n",
      "ahbs LGB2: ✓ Loaded\n",
      "cw LGB1: ✓ Loaded\n",
      "cw LGB2: ✓ Loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def load_lgb_models(model_paths_dict):\n",
    "    loaded_models = {}\n",
    "\n",
    "    for error_type in model_paths_dict:\n",
    "        loaded_models[error_type] = {}\n",
    "\n",
    "        for model_name, path in model_paths_dict[error_type].items():\n",
    "            try:\n",
    "                path = path.replace('\\\\', '/')  # Normalize path\n",
    "                if not os.path.exists(path):\n",
    "                    print(f\"✗ {error_type} {model_name}: File not found at {path}\")\n",
    "                    loaded_models[error_type][model_name] = None\n",
    "                    continue\n",
    "\n",
    "                print(f\"Loading {error_type} {model_name}...\")\n",
    "                model = lgb.Booster(model_file=path)\n",
    "                print(f\"✓ Model loaded successfully\")\n",
    "\n",
    "                loaded_models[error_type][model_name] = model\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Failed to load {error_type} {model_name}: {str(e)}\")\n",
    "                loaded_models[error_type][model_name] = None\n",
    "\n",
    "    return loaded_models\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Model paths dictionary with proper path handling for Windows\n",
    "    # Use forward slashes or raw strings to avoid Unicode escape errors\n",
    "    model_paths_dict = {\n",
    "    'bs': {\n",
    "        'LGB1': r\"C:/Users/maxva/OneDrive - Tilburg University/Msc. Data Science/Master Thesis/Code/Models/LigthGBM Forecast/Option only/LightGBM forecast option_h1/LGB1_bs_model.txt\",\n",
    "        'LGB2': r\"C:/Users/maxva/OneDrive - Tilburg University/Msc. Data Science/Master Thesis/Code/Models/LigthGBM Forecast/Option only/LightGBM forecast option_h1/LGB2_bs_model.txt\"\n",
    "    },\n",
    "    'ahbs': {\n",
    "        'LGB1': r\"C:/Users/maxva/OneDrive - Tilburg University/Msc. Data Science/Master Thesis/Code/Models/LigthGBM Forecast/Option only/LightGBM forecast option_h1/LGB1_ahbs_model.txt\",\n",
    "        'LGB2': r\"C:/Users/maxva/OneDrive - Tilburg University/Msc. Data Science/Master Thesis/Code/Models/LigthGBM Forecast/Option only/LightGBM forecast option_h1/LGB2_ahbs_model.txt\"\n",
    "    },\n",
    "    'cw': {\n",
    "        'LGB1': r\"C:/Users/maxva/OneDrive - Tilburg University/Msc. Data Science/Master Thesis/Code/Models/LigthGBM Forecast/Option only/LightGBM forecast option_h1/LGB1_cw_model.txt\",\n",
    "        'LGB2': r\"C:/Users/maxva/OneDrive - Tilburg University/Msc. Data Science/Master Thesis/Code/Models/LigthGBM Forecast/Option only/LightGBM forecast option_h1/LGB2_cw_model.txt\"\n",
    "    }\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Load all models\n",
    "    loaded_models = load_lgb_models(model_paths_dict)\n",
    "    \n",
    "    # Print summary of loaded models\n",
    "    print(\"\\n=== Model Loading Summary ===\")\n",
    "    for error_type in loaded_models:\n",
    "        for model_name in loaded_models[error_type]:\n",
    "            status = \"✓ Loaded\" if loaded_models[error_type][model_name] is not None else \"✗ Failed\"\n",
    "            print(f\"{error_type} {model_name}: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2b9773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "43a794ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Horizon 1 ===\n",
      "Feature columns: ['cp_flag', 'stock_price', 'moneyness', 'time_to_expiry', 'strike_price', 'rf', 'delta', 'gamma', 'vega', 'theta']\n",
      "\n",
      "-- Predicting corrections for BS --\n",
      "   impl_volatility     iv_bs  iv_bs_pred_LGB1  iv_bs_corrected_LGB1  \\\n",
      "0         0.201081  0.288808        -0.065495              0.223312   \n",
      "1         0.196421  0.288808        -0.068675              0.220132   \n",
      "2         0.191262  0.288808        -0.072360              0.216447   \n",
      "\n",
      "   iv_bs_pred_LGB2  iv_bs_corrected_LGB2  \n",
      "0        -0.072925              0.215882  \n",
      "1        -0.074356              0.214451  \n",
      "2        -0.076221              0.212587  \n",
      "\n",
      "-- Predicting corrections for AHBS --\n",
      "   impl_volatility   iv_ahbs  iv_ahbs_pred_LGB1  iv_ahbs_corrected_LGB1  \\\n",
      "0         0.201081  0.299345          -0.066698                0.232647   \n",
      "1         0.196421  0.298947          -0.069551                0.229396   \n",
      "2         0.191262  0.298851          -0.069363                0.229488   \n",
      "\n",
      "   iv_ahbs_pred_LGB2  iv_ahbs_corrected_LGB2  \n",
      "0          -0.065910                0.233435  \n",
      "1          -0.068042                0.230905  \n",
      "2          -0.068120                0.230730  \n",
      "\n",
      "-- Predicting corrections for CW --\n",
      "   impl_volatility     iv_cw  iv_cw_pred_LGB1  iv_cw_corrected_LGB1  \\\n",
      "0         0.201081  0.264812        -0.039876              0.224936   \n",
      "1         0.196421  0.266365        -0.041552              0.224813   \n",
      "2         0.191262  0.269537        -0.044377              0.225160   \n",
      "\n",
      "   iv_cw_pred_LGB2  iv_cw_corrected_LGB2  \n",
      "0        -0.039258              0.225554  \n",
      "1        -0.041371              0.224995  \n",
      "2        -0.043987              0.225550  \n",
      "\n",
      "✓ option_only_data[1] updated.\n",
      "\n",
      "=== Horizon 5 ===\n",
      "Feature columns: ['cp_flag', 'stock_price', 'moneyness', 'time_to_expiry', 'strike_price', 'rf', 'delta', 'gamma', 'vega', 'theta']\n",
      "\n",
      "-- Predicting corrections for BS --\n",
      "   impl_volatility     iv_bs  iv_bs_pred_LGB1  iv_bs_corrected_LGB1  \\\n",
      "0         0.246879  0.288808        -0.051843              0.236964   \n",
      "1         0.243913  0.288808        -0.059111              0.229696   \n",
      "2         0.239469  0.288808        -0.062261              0.226546   \n",
      "\n",
      "   iv_bs_pred_LGB2  iv_bs_corrected_LGB2  \n",
      "0        -0.069095              0.219713  \n",
      "1        -0.071313              0.217495  \n",
      "2        -0.071578              0.217230  \n",
      "\n",
      "-- Predicting corrections for AHBS --\n",
      "   impl_volatility   iv_ahbs  iv_ahbs_pred_LGB1  iv_ahbs_corrected_LGB1  \\\n",
      "0         0.246879  0.296150          -0.052450                0.243700   \n",
      "1         0.243913  0.295814          -0.056674                0.239140   \n",
      "2         0.239469  0.295779          -0.058275                0.237505   \n",
      "\n",
      "   iv_ahbs_pred_LGB2  iv_ahbs_corrected_LGB2  \n",
      "0          -0.060538                0.235612  \n",
      "1          -0.063528                0.232286  \n",
      "2          -0.062198                0.233581  \n",
      "\n",
      "-- Predicting corrections for CW --\n",
      "   impl_volatility     iv_cw  iv_cw_pred_LGB1  iv_cw_corrected_LGB1  \\\n",
      "0         0.246879  0.263030        -0.025611              0.237419   \n",
      "1         0.243913  0.264520        -0.033081              0.231439   \n",
      "2         0.239469  0.267565        -0.031652              0.235913   \n",
      "\n",
      "   iv_cw_pred_LGB2  iv_cw_corrected_LGB2  \n",
      "0        -0.033509              0.229521  \n",
      "1        -0.037375              0.227145  \n",
      "2        -0.037802              0.229764  \n",
      "\n",
      "✓ option_only_data[5] updated.\n",
      "\n",
      "=== Horizon 21 ===\n",
      "Feature columns: ['cp_flag', 'stock_price', 'moneyness', 'time_to_expiry', 'strike_price', 'rf', 'delta', 'gamma', 'vega', 'theta']\n",
      "\n",
      "-- Predicting corrections for BS --\n",
      "   impl_volatility     iv_bs  iv_bs_pred_LGB1  iv_bs_corrected_LGB1  \\\n",
      "0         0.159662  0.288808        -0.072959              0.215849   \n",
      "1         0.153761  0.288808        -0.074190              0.214618   \n",
      "2         0.146285  0.288808        -0.073270              0.215537   \n",
      "\n",
      "   iv_bs_pred_LGB2  iv_bs_corrected_LGB2  \n",
      "0        -0.074645              0.214163  \n",
      "1        -0.074462              0.214345  \n",
      "2        -0.068936              0.219871  \n",
      "\n",
      "-- Predicting corrections for AHBS --\n",
      "   impl_volatility   iv_ahbs  iv_ahbs_pred_LGB1  iv_ahbs_corrected_LGB1  \\\n",
      "0         0.159662  0.274520          -0.050133                0.224387   \n",
      "1         0.153761  0.283228          -0.056982                0.226246   \n",
      "2         0.146285  0.296779          -0.057098                0.239681   \n",
      "\n",
      "   iv_ahbs_pred_LGB2  iv_ahbs_corrected_LGB2  \n",
      "0          -0.055365                0.219155  \n",
      "1          -0.059035                0.224193  \n",
      "2          -0.057013                0.239766  \n",
      "\n",
      "-- Predicting corrections for CW --\n",
      "   impl_volatility     iv_cw  iv_cw_pred_LGB1  iv_cw_corrected_LGB1  \\\n",
      "0         0.159662  0.261731        -0.052879              0.208852   \n",
      "1         0.153761  0.294981        -0.069564              0.225417   \n",
      "2         0.146285  0.342147        -0.082830              0.259317   \n",
      "\n",
      "   iv_cw_pred_LGB2  iv_cw_corrected_LGB2  \n",
      "0        -0.053135              0.208596  \n",
      "1        -0.068814              0.226167  \n",
      "2        -0.080597              0.261549  \n",
      "\n",
      "✓ option_only_data[21] updated.\n"
     ]
    }
   ],
   "source": [
    "test_data_per_horizon = {}\n",
    "\n",
    "\n",
    "scaler_path = r\"C:\\Users\\maxva\\OneDrive - Tilburg University\\Msc. Data Science\\Master Thesis\\Code\\Models\\LigthGBM Forecast\\Option only\\LightGBM forecast option_h1\\scaler.pkl\"\n",
    "\n",
    "# Load the scaler\n",
    "scaler = joblib.load(scaler_path)\n",
    "for horizon in horizons:\n",
    "    print(f\"\\n=== Horizon {horizon} ===\")\n",
    "    \n",
    "    # 1) Copy base test set\n",
    "    base_df = option_only_data[horizon].copy()\n",
    "    \n",
    "    # 2) Define features (remove target + metadata columns)\n",
    "    exclude_cols = [\n",
    "        'iv_bs_error','iv_ahbs','iv_ahbs_error','iv_bs','iv_cw','iv_cw_error',\n",
    "        'impl_volatility','moneyness_category','ID','date','new_id',\n",
    "        'open_interest','option_price','prediction_horizon',\n",
    "        'test_date','train_date','volume', 'iv_ahbs_corrected_LGB1', 'iv_ahbs_corrected_LGB2',\n",
    "        'iv_bs_corrected_LGB2', 'iv_cw_corrected_LGB1', 'iv_cw_corrected_LGB2',\n",
    "        'iv_bs_pred_LGB1', 'iv_bs_pred_LGB2', 'iv_cw_pred_LGB1', 'iv_cw_pred_LGB2',\n",
    "        'iv_ahbs_pred_LGB1', 'iv_ahbs_pred_LGB2', 'iv_bs_corrected_LGB1']\n",
    "\n",
    "    feature_columns = [c for c in base_df.columns if c not in exclude_cols]\n",
    "    print(f\"Feature columns: {feature_columns}\")\n",
    "    \n",
    "    # 3) Add model predictions and corrections\n",
    "    df = base_df\n",
    "    for error_type in ['bs', 'ahbs', 'cw']:\n",
    "        print(f\"\\n-- Predicting corrections for {error_type.upper()} --\")\n",
    "        \n",
    "        models_for_type = loaded_models[error_type]  # {'LGB1': model_obj, 'NN4': model_obj}\n",
    "        \n",
    "        # This helper must add pred/corrected cols in-place\n",
    "        df = predict_and_add_to_test_data(\n",
    "            models=models_for_type,\n",
    "            test_data=df,\n",
    "            scaler=scaler,\n",
    "            feature_columns=feature_columns,\n",
    "            error_type=error_type\n",
    "        )\n",
    "        \n",
    "        # Preview new prediction columns\n",
    "        cols = ['impl_volatility', f'iv_{error_type}']\n",
    "        for model in ['LGB1', 'LGB2']:\n",
    "            cols += [f'iv_{error_type}_pred_{model}', f'iv_{error_type}_corrected_{model}']\n",
    "        print(df[cols].head(3))\n",
    "    \n",
    "    # 4) Store final result for this horizon\n",
    "    option_only_data[horizon] = df.copy()\n",
    "    print(f\"\\n✓ option_only_data[{horizon}] updated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "313fc8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (2571058, 29)\n",
      "Columns: ['cp_flag', 'stock_price', 'moneyness', 'time_to_expiry', 'strike_price', 'rf', 'delta', 'gamma', 'vega', 'theta', 'iv_ahbs', 'iv_ahbs_error', 'iv_bs', 'iv_bs_error', 'iv_cw', 'iv_cw_error', 'impl_volatility', 'iv_bs_pred_LGB1', 'iv_bs_corrected_LGB1', 'iv_bs_pred_LGB2', 'iv_bs_corrected_LGB2', 'iv_ahbs_pred_LGB1', 'iv_ahbs_corrected_LGB1', 'iv_ahbs_pred_LGB2', 'iv_ahbs_corrected_LGB2', 'iv_cw_pred_LGB1', 'iv_cw_corrected_LGB1', 'iv_cw_pred_LGB2', 'iv_cw_corrected_LGB2']\n"
     ]
    }
   ],
   "source": [
    "df = option_only_data[1]              # haal de DataFrame uit de dict\n",
    "print(f\"df shape: {df.shape}\")        # tuple (n_rows, n_cols)\n",
    "print(f\"Columns: {df.columns.tolist()}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f2b159",
   "metadata": {},
   "source": [
    "Calculate IVRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a93a615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Added moneyness categories to option_only_data for horizon 1\n",
      "\n",
      "Sample data for horizon 1:\n",
      "   cp_flag  moneyness moneyness_category\n",
      "0        1   0.996078                ATM\n",
      "1        1   0.987564                ATM\n",
      "2        1   0.979195                ATM\n",
      "3        1   0.970966                ATM\n",
      "4        1   0.962875               OTMC\n",
      "✓ Added moneyness categories to option_only_data for horizon 5\n",
      "\n",
      "Sample data for horizon 5:\n",
      "   cp_flag  moneyness moneyness_category\n",
      "0        1   0.996078                ATM\n",
      "1        1   0.987564                ATM\n",
      "2        1   0.979195                ATM\n",
      "3        1   0.970966                ATM\n",
      "4        1   0.962875               OTMC\n",
      "✓ Added moneyness categories to option_only_data for horizon 21\n",
      "\n",
      "Sample data for horizon 21:\n",
      "   cp_flag  moneyness moneyness_category\n",
      "0        1   0.962875               OTMC\n",
      "1        1   0.924360               OTMC\n",
      "2        1   0.888808              DOTMC\n",
      "3        1   0.855889              DOTMC\n",
      "4        0   1.155450              DOTMP\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def add_moneyness_categories(df):\n",
    "    # Create a copy to avoid modifying the original dataframe\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Initialize moneyness_category column explicitly as object dtype\n",
    "    result['moneyness_category'] = np.nan\n",
    "    result['moneyness_category'] = result['moneyness_category'].astype('object')\n",
    "    \n",
    "    # Define conditions for each category\n",
    "    dotmc_mask = (result['cp_flag'] == 1) & (result['moneyness'] >= 0.80) & (result['moneyness'] < 0.90)\n",
    "    otmc_mask = (result['cp_flag'] == 1) & (result['moneyness'] >= 0.90) & (result['moneyness'] < 0.97)\n",
    "    atm_mask   = (result['moneyness'] >= 0.97) & (result['moneyness'] < 1.03)\n",
    "    otmp_mask  = (result['cp_flag'] == 0) & (result['moneyness'] >= 1.03) & (result['moneyness'] < 1.10)\n",
    "    dotmp_mask = (result['cp_flag'] == 0) & (result['moneyness'] >= 1.10) & (result['moneyness'] <= 1.60)\n",
    "    \n",
    "    # Assign categories based on conditions\n",
    "    result.loc[dotmc_mask, 'moneyness_category'] = 'DOTMC'\n",
    "    result.loc[otmc_mask, 'moneyness_category'] = 'OTMC'\n",
    "    result.loc[atm_mask,   'moneyness_category'] = 'ATM'\n",
    "    result.loc[otmp_mask,  'moneyness_category'] = 'OTMP'\n",
    "    result.loc[dotmp_mask, 'moneyness_category'] = 'DOTMP'\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Apply the function to each horizon\n",
    "for horizon in [1, 5, 21]:\n",
    "    option_only_data[horizon] = add_moneyness_categories(option_only_data[horizon])\n",
    "    print(f\"✓ Added moneyness categories to option_only_data for horizon {horizon}\")\n",
    "    \n",
    "    display_columns = ['cp_flag', 'moneyness', 'moneyness_category']\n",
    "    print(f\"\\nSample data for horizon {horizon}:\")\n",
    "    print(option_only_data[horizon][display_columns].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6292a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DOTMC': {'bs_base': np.float64(0.12766750645454028), 'bs_LGB1': np.float64(0.05282349893022591), 'bs_LGB1_improvement': np.float64(58.62416334650098), 'bs_LGB2': np.float64(0.05970526137921827), 'bs_LGB2_improvement': np.float64(53.23378435336006), 'ahbs_base': np.float64(0.12243300045171161), 'ahbs_LGB1': np.float64(0.044122637118434845), 'ahbs_LGB1_improvement': np.float64(63.96181016911604), 'ahbs_LGB2': np.float64(0.0493266457332119), 'ahbs_LGB2_improvement': np.float64(59.711315126458366), 'cw_base': np.float64(0.11351418965472203), 'cw_LGB1': np.float64(0.0416523238285554), 'cw_LGB1_improvement': np.float64(63.30650471518147), 'cw_LGB2': np.float64(0.045681622961231974), 'cw_LGB2_improvement': np.float64(59.756905193806595)}, 'OTMC': {'bs_base': np.float64(0.11784078504428586), 'bs_LGB1': np.float64(0.04458959381584167), 'bs_LGB1_improvement': np.float64(62.16115345880935), 'bs_LGB2': np.float64(0.05002263125445833), 'bs_LGB2_improvement': np.float64(57.55066360457521), 'ahbs_base': np.float64(0.11010342712185493), 'ahbs_LGB1': np.float64(0.041736444547615215), 'ahbs_LGB1_improvement': np.float64(62.093419216257296), 'ahbs_LGB2': np.float64(0.046511790855863405), 'ahbs_LGB2_improvement': np.float64(57.75627328621902), 'cw_base': np.float64(0.10871489581893092), 'cw_LGB1': np.float64(0.040585707474425865), 'cw_LGB1_improvement': np.float64(62.66775848084054), 'cw_LGB2': np.float64(0.04501587977962224), 'cw_LGB2_improvement': np.float64(58.592721410874525)}, 'ATM': {'bs_base': np.float64(0.11533237841556095), 'bs_LGB1': np.float64(0.04287221526000095), 'bs_LGB1_improvement': np.float64(62.827251246371155), 'bs_LGB2': np.float64(0.04825392729993134), 'bs_LGB2_improvement': np.float64(58.160988299344055), 'ahbs_base': np.float64(0.11098712532583264), 'ahbs_LGB1': np.float64(0.04292058095978173), 'ahbs_LGB1_improvement': np.float64(61.3283244936953), 'ahbs_LGB2': np.float64(0.04820194311694142), 'ahbs_LGB2_improvement': np.float64(56.569788635004635), 'cw_base': np.float64(0.10887641823132291), 'cw_LGB1': np.float64(0.0432541237140894), 'cw_LGB1_improvement': np.float64(60.2722752853698), 'cw_LGB2': np.float64(0.048622714647738006), 'cw_LGB2_improvement': np.float64(55.341371953996166)}, 'OTMP': {'bs_base': np.float64(0.10848452923890609), 'bs_LGB1': np.float64(0.04360001869209139), 'bs_LGB1_improvement': np.float64(59.80992036562666), 'bs_LGB2': np.float64(0.04822061991672477), 'bs_LGB2_improvement': np.float64(55.5506944123501), 'ahbs_base': np.float64(0.10625185327498543), 'ahbs_LGB1': np.float64(0.04468470949432734), 'ahbs_LGB1_improvement': np.float64(57.944536384997505), 'ahbs_LGB2': np.float64(0.04964101239914708), 'ahbs_LGB2_improvement': np.float64(53.27986207386566), 'cw_base': np.float64(0.1052322294590815), 'cw_LGB1': np.float64(0.04448111225478594), 'cw_LGB1_improvement': np.float64(57.73052373457319), 'cw_LGB2': np.float64(0.04913233833426941), 'cw_LGB2_improvement': np.float64(53.31056028478991)}, 'DOTMP': {'bs_base': np.float64(0.16901681276488947), 'bs_LGB1': np.float64(0.04983734078182336), 'bs_LGB1_improvement': np.float64(70.51338268273376), 'bs_LGB2': np.float64(0.057525284922588196), 'bs_LGB2_improvement': np.float64(65.96475582425718), 'ahbs_base': np.float64(0.1176032754986951), 'ahbs_LGB1': np.float64(0.051927138923503396), 'ahbs_LGB1_improvement': np.float64(55.84549945287913), 'ahbs_LGB2': np.float64(0.058165593644639815), 'ahbs_LGB2_improvement': np.float64(50.54083876661649), 'cw_base': np.float64(0.11209416748222316), 'cw_LGB1': np.float64(0.05082005509756597), 'cw_LGB1_improvement': np.float64(54.663069239864384), 'cw_LGB2': np.float64(0.05618893220227607), 'cw_LGB2_improvement': np.float64(49.873455984061806)}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "moneyness_groups = ['DOTMC', 'OTMC', 'ATM', 'OTMP', 'DOTMP']\n",
    "\n",
    "def analyze_ivrmse_by_moneyness(test_data):\n",
    "\n",
    "    # 1. Group the test data by moneyness\n",
    "    results = {}\n",
    "    for group in moneyness_groups:\n",
    "        group_data = test_data[test_data['moneyness_category'] == group]\n",
    "        \n",
    "        # Skip if no data in this group\n",
    "        if len(group_data) == 0:\n",
    "            print(f\"Warning: No data found for moneyness group {group}\")\n",
    "            continue\n",
    "            \n",
    "        # Initialize results for this group\n",
    "        results[group] = {}\n",
    "        \n",
    "        # 2. Calculate IVRMSE for each error type and model\n",
    "        for error_type in ['bs', 'ahbs', 'cw']:\n",
    "            # Column names\n",
    "            orig_col = f'iv_{error_type}'\n",
    "            \n",
    "            # Skip if column doesn't exist\n",
    "            if orig_col not in group_data.columns:\n",
    "                print(f\"Warning: Column {orig_col} not found, skipping...\")\n",
    "                continue\n",
    "                \n",
    "            # Calculate baseline IVRMSE\n",
    "            base_rmse = np.sqrt(mean_squared_error(\n",
    "                group_data['impl_volatility'], \n",
    "                group_data[orig_col]\n",
    "            ))\n",
    "            \n",
    "            # Store baseline IVRMSE\n",
    "            results[group][f\"{error_type}_base\"] = base_rmse\n",
    "            \n",
    "            # Calculate corrected IVRMSE for each model\n",
    "            for model in ['LGB1', 'LGB2']:\n",
    "                corrected_col = f'iv_{error_type}_corrected_{model}'\n",
    "                \n",
    "                # Skip if column doesn't exist\n",
    "                if corrected_col not in group_data.columns:\n",
    "                    print(f\"Warning: Column {corrected_col} not found, skipping...\")\n",
    "                    continue\n",
    "                    \n",
    "                corrected_rmse = np.sqrt(mean_squared_error(\n",
    "                    group_data['impl_volatility'], \n",
    "                    group_data[corrected_col]\n",
    "                ))\n",
    "                \n",
    "                # Calculate improvement percentage\n",
    "                improvement = (base_rmse - corrected_rmse) / base_rmse * 100\n",
    "                \n",
    "                # Store results\n",
    "                results[group][f\"{error_type}_{model}\"] = corrected_rmse\n",
    "                results[group][f\"{error_type}_{model}_improvement\"] = improvement\n",
    "    \n",
    "    return results\n",
    "\n",
    "def format_results_table(results):\n",
    "    # Prepare IVRMSE table data\n",
    "    ivrmse_data = []\n",
    "    for group, group_results in results.items():\n",
    "        row = {'Moneyness Group': group}\n",
    "        \n",
    "        for key, value in group_results.items():\n",
    "            if not key.endswith('improvement'):\n",
    "                if key.endswith('base'):\n",
    "                    # Format baseline columns\n",
    "                    error_type = key.split('_')[0].upper()\n",
    "                    row[f\"{error_type} Base\"] = value\n",
    "                else:\n",
    "                    # Format model columns\n",
    "                    parts = key.split('_')\n",
    "                    error_type = parts[0].upper()\n",
    "                    model = parts[1]\n",
    "                    row[f\"{error_type} {model}\"] = value\n",
    "        \n",
    "        ivrmse_data.append(row)\n",
    "    \n",
    "    # Prepare improvement percentage table data\n",
    "    improvement_data = []\n",
    "    for group, group_results in results.items():\n",
    "        row = {'Moneyness Group': group}\n",
    "        \n",
    "        for key, value in group_results.items():\n",
    "            if key.endswith('improvement'):\n",
    "                # Format improvement columns\n",
    "                parts = key.replace('_improvement', '').split('_')\n",
    "                error_type = parts[0].upper()\n",
    "                model = parts[1]\n",
    "                row[f\"{error_type} {model}\"] = value\n",
    "        \n",
    "        improvement_data.append(row)\n",
    "    \n",
    "    # Create DataFrames\n",
    "    ivrmse_df = pd.DataFrame(ivrmse_data)\n",
    "    improvement_df = pd.DataFrame(improvement_data)\n",
    "    \n",
    "    # Sort columns for better readability\n",
    "    ivrmse_cols = ['Moneyness Group']\n",
    "    improvement_cols = ['Moneyness Group']\n",
    "    \n",
    "    for et in ['BS', 'AHBS', 'CW']:\n",
    "        ivrmse_cols.extend([f\"{et} Base\", f\"{et} LGB1\", f\"{et} LGB2\"])\n",
    "        improvement_cols.extend([f\"{et} LGB1\", f\"{et} LGB2\"])\n",
    "    \n",
    "    # Reorder columns if they exist\n",
    "    ivrmse_df = ivrmse_df[[col for col in ivrmse_cols if col in ivrmse_df.columns]]\n",
    "    improvement_df = improvement_df[[col for col in improvement_cols if col in improvement_df.columns]]\n",
    "    \n",
    "    return ivrmse_df, improvement_df\n",
    "\n",
    "def find_best_models(results):\n",
    "    best_models = []\n",
    "    \n",
    "    for group, group_results in results.items():\n",
    "        for error_type in ['bs', 'ahbs', 'cw']:\n",
    "            # Get baseline IVRMSE\n",
    "            base_key = f\"{error_type}_base\"\n",
    "            if base_key not in group_results:\n",
    "                continue\n",
    "                \n",
    "            base_rmse = group_results[base_key]\n",
    "            \n",
    "            # Find best model for this error type\n",
    "            models = [m for m in ['LGB1', 'LGB2'] if f\"{error_type}_{m}\" in group_results]\n",
    "            if not models:\n",
    "                continue\n",
    "            \n",
    "            # Find model with lowest IVRMSE    \n",
    "            best_model = min(models, key=lambda m: group_results[f\"{error_type}_{m}\"])\n",
    "            best_rmse = group_results[f\"{error_type}_{best_model}\"]\n",
    "            improvement = group_results[f\"{error_type}_{best_model}_improvement\"]\n",
    "            \n",
    "            # Also get the values for the other model for comparison\n",
    "            other_models = [m for m in models if m != best_model]\n",
    "            other_model_data = {}\n",
    "            if other_models:\n",
    "                other_model = other_models[0]\n",
    "                other_rmse = group_results[f\"{error_type}_{other_model}\"]\n",
    "                other_improvement = group_results[f\"{error_type}_{other_model}_improvement\"]\n",
    "                other_model_data = {\n",
    "                    f'Other Model': other_model,\n",
    "                    f'Other IVRMSE': other_rmse,\n",
    "                    f'Other Improvement %': other_improvement\n",
    "                }\n",
    "            \n",
    "            model_data = {\n",
    "                'Moneyness Group': group,\n",
    "                'Error Type': error_type.upper(),\n",
    "                'Best Model': best_model,\n",
    "                'Base IVRMSE': base_rmse,\n",
    "                'Best IVRMSE': best_rmse,\n",
    "                'Improvement %': improvement\n",
    "            }\n",
    "            \n",
    "            # Add other model data if available\n",
    "            model_data.update(other_model_data)\n",
    "            \n",
    "            best_models.append(model_data)\n",
    "    \n",
    "    return pd.DataFrame(best_models)\n",
    "\n",
    "def print_formatted_tables(results):\n",
    "    \"\"\"\n",
    "    Print formatted tables from the analysis results.\n",
    "    \n",
    "    Parameters:\n",
    "    results (dict): Results from analyze_ivrmse_by_moneyness function\n",
    "    \"\"\"\n",
    "    # Format results into DataFrames\n",
    "    ivrmse_df, improvement_df = format_results_table(results)\n",
    "    \n",
    "    # Format IVRMSE table\n",
    "    pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"IVRMSE by Moneyness Group (Horizon: {horizon})\")\n",
    "    print(\"=\" * 80)\n",
    "    print(ivrmse_df.to_string(index=False))\n",
    "    \n",
    "    # Format improvement table\n",
    "    pd.set_option('display.float_format', '{:.2f}%'.format)\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Improvement Percentage by Moneyness Group\")\n",
    "    print(\"=\" * 80)\n",
    "    print(improvement_df.to_string(index=False))\n",
    "    \n",
    "    # Find best models\n",
    "    best_models_df = find_best_models(results)\n",
    "    \n",
    "    # Reset float format for mixed table\n",
    "    pd.set_option('display.float_format', None)\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Best Model by Moneyness Group and Error Type\")\n",
    "    print(\"=\" * 80)\n",
    "    # Format specific columns\n",
    "    best_models_df['Base IVRMSE'] = best_models_df['Base IVRMSE'].map('{:.6f}'.format)\n",
    "    best_models_df['Best IVRMSE'] = best_models_df['Best IVRMSE'].map('{:.6f}'.format)\n",
    "    best_models_df['Improvement %'] = best_models_df['Improvement %'].map('{:.2f}%'.format)\n",
    "    print(best_models_df.to_string(index=False))\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Summary Statistics\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Count best model occurrences\n",
    "    model_counts = best_models_df['Best Model'].value_counts()\n",
    "    print(f\"Overall best model distribution: {dict(model_counts)}\")\n",
    "    \n",
    "    # Average improvement by moneyness group\n",
    "    print(\"\\nAverage improvement by moneyness group:\")\n",
    "    # Convert percentage strings to numeric values\n",
    "    best_models_df['Improvement_Numeric'] = pd.to_numeric(best_models_df['Improvement %'].str.rstrip('%'))\n",
    "    \n",
    "    # Group and calculate means\n",
    "    avg_improvement = best_models_df.groupby('Moneyness Group')['Improvement_Numeric'].mean()\n",
    "    \n",
    "    # Handle the case where there's only one group (which returns a scalar)\n",
    "    if isinstance(avg_improvement, pd.Series):\n",
    "        # Sort if it's a Series with multiple values\n",
    "        sorted_improvements = avg_improvement.sort_values(ascending=False)\n",
    "        for group, imp in sorted_improvements.items():\n",
    "            print(f\"  {group}: {imp:.2f}%\")\n",
    "    else:\n",
    "        # Just print the single value if it's a scalar\n",
    "        group = best_models_df['Moneyness Group'].iloc[0]\n",
    "        print(f\"  {group}: {avg_improvement:.2f}%\")\n",
    "\n",
    "# Example usage:\n",
    "results_h1 = analyze_ivrmse_by_moneyness(option_only_data[1])\n",
    "results_h5 = analyze_ivrmse_by_moneyness(option_only_data[5])\n",
    "results_h21 = analyze_ivrmse_by_moneyness(option_only_data[21])\n",
    "print(results_h1)\n",
    "\n",
    "# To get the results as DataFrames for further analysis:\n",
    "#ivrmse_df, improvement_df = format_results_table(results)\n",
    "#best_models_df = find_best_models(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b089598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== IVRMSE Results 1 ===\n",
      "Model           IVRMSE     Improvement \n",
      "----------------------------------------\n",
      "BS              0.130376  (baseline)  \n",
      "bs_LGB1         0.046650  64.22%\n",
      "bs_LGB2         0.052728  59.56%\n",
      "----------------------------------------\n",
      "AHBS            0.113431  (baseline)  \n",
      "ahbs_LGB1       0.045207  60.15%\n",
      "ahbs_LGB2       0.050533  55.45%\n",
      "----------------------------------------\n",
      "CW              0.109746  (baseline)  \n",
      "cw_LGB1         0.044338  59.60%\n",
      "cw_LGB2         0.049168  55.20%\n",
      "----------------------------------------\n",
      "\n",
      "Best overall model: cw_LGB1 with IVRMSE = 0.044338\n",
      "Improvement over baseline: 59.60%\n",
      "\n",
      "=== IVRMSE Results 5 ===\n",
      "Model           IVRMSE     Improvement \n",
      "----------------------------------------\n",
      "BS              0.131012  (baseline)  \n",
      "bs_LGB1         0.058578  55.29%\n",
      "bs_LGB2         0.062664  52.17%\n",
      "----------------------------------------\n",
      "AHBS            0.114337  (baseline)  \n",
      "ahbs_LGB1       0.056840  50.29%\n",
      "ahbs_LGB2       0.060271  47.29%\n",
      "----------------------------------------\n",
      "CW              0.111210  (baseline)  \n",
      "cw_LGB1         0.056149  49.51%\n",
      "cw_LGB2         0.059266  46.71%\n",
      "----------------------------------------\n",
      "\n",
      "Best overall model: cw_LGB1 with IVRMSE = 0.056149\n",
      "Improvement over baseline: 49.51%\n",
      "\n",
      "=== IVRMSE Results 21 ===\n",
      "Model           IVRMSE     Improvement \n",
      "----------------------------------------\n",
      "BS              0.134095  (baseline)  \n",
      "bs_LGB1         0.079640  40.61%\n",
      "bs_LGB2         0.082451  38.51%\n",
      "----------------------------------------\n",
      "AHBS            0.118062  (baseline)  \n",
      "ahbs_LGB1       0.076809  34.94%\n",
      "ahbs_LGB2       0.078930  33.15%\n",
      "----------------------------------------\n",
      "CW              0.115817  (baseline)  \n",
      "cw_LGB1         0.076351  34.08%\n",
      "cw_LGB2         0.078201  32.48%\n",
      "----------------------------------------\n",
      "\n",
      "Best overall model: cw_LGB1 with IVRMSE = 0.076351\n",
      "Improvement over baseline: 34.08%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_ivrmse(predictions_df, error_types=['bs', 'ahbs', 'cw'], models=['LGB1', 'LGB2']):\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    # Calculate IVRMSE for each error type and model\n",
    "    for error_type in error_types:\n",
    "        orig_col = f'iv_{error_type}'\n",
    "        \n",
    "        # Calculate base IVRMSE (before correction)\n",
    "        base_rmse = np.sqrt(mean_squared_error(predictions_df['impl_volatility'], predictions_df[orig_col]))\n",
    "        results[f\"{error_type}_base\"] = base_rmse\n",
    "        \n",
    "        # Calculate IVRMSE for each model\n",
    "        for model in models:\n",
    "            corrected_col = f'iv_{error_type}_corrected_{model}'\n",
    "            \n",
    "            # Skip if corrected column doesn't exist\n",
    "            if corrected_col not in predictions_df.columns:\n",
    "                print(f\"Warning: {corrected_col} column not found, skipping...\")\n",
    "                continue\n",
    "                \n",
    "            # Calculate IVRMSE for the corrected predictions\n",
    "            corrected_rmse = np.sqrt(mean_squared_error(predictions_df['impl_volatility'], predictions_df[corrected_col]))\n",
    "            results[f\"{error_type}_{model}\"] = corrected_rmse\n",
    "            \n",
    "            # Calculate improvement percentage\n",
    "            improvement = (base_rmse - corrected_rmse) / base_rmse * 100\n",
    "            results[f\"{error_type}_{model}_improvement\"] = improvement\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "for horizon in horizons:\n",
    "    if __name__ == \"__main__\":\n",
    "        # Calculate IVRMSE\n",
    "        ivrmse_results = calculate_ivrmse(option_only_data[horizon])\n",
    "        \n",
    "        # Print results in a table format\n",
    "        print(f\"\\n=== IVRMSE Results {horizon} ===\")\n",
    "        print(f\"{'Model':<15} {'IVRMSE':<10} {'Improvement':<12}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for error_type in ['bs', 'ahbs', 'cw']:\n",
    "            base_key = f\"{error_type}_base\"\n",
    "            if base_key in ivrmse_results:\n",
    "                base_rmse = ivrmse_results[base_key]\n",
    "                print(f\"{error_type.upper():<15} {base_rmse:.6f}  {'(baseline)':<12}\")\n",
    "                \n",
    "                for model in ['LGB1', 'LGB2']:\n",
    "                    model_key = f\"{error_type}_{model}\"\n",
    "                    imp_key = f\"{error_type}_{model}_improvement\"\n",
    "                    \n",
    "                    if model_key in ivrmse_results:\n",
    "                        print(f\"{model_key:<15} {ivrmse_results[model_key]:.6f}  {ivrmse_results[imp_key]:.2f}%\")\n",
    "                print(\"-\" * 40)\n",
    "        \n",
    "        # Find best overall model\n",
    "        model_keys = [k for k in ivrmse_results.keys() if not k.endswith('base') and not k.endswith('improvement')]\n",
    "        if model_keys:\n",
    "            best_model = min(model_keys, key=lambda k: ivrmse_results[k])\n",
    "            print(f\"\\nBest overall model: {best_model} with IVRMSE = {ivrmse_results[best_model]:.6f}\")\n",
    "            \n",
    "            base_key = f\"{best_model.split('_')[0]}_base\"\n",
    "            imp_key = f\"{best_model}_improvement\"\n",
    "            if base_key in ivrmse_results and imp_key in ivrmse_results:\n",
    "                print(f\"Improvement over baseline: {ivrmse_results[imp_key]:.2f}%\")\n",
    "                \n",
    "        # Export results to CSV for further analysis\n",
    "        results_df = pd.DataFrame({\n",
    "            'Model': list(ivrmse_results.keys()),\n",
    "            'Value': list(ivrmse_results.values())\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05488a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "IVRMSE by Moneyness Group (Horizon: 1)\n",
      "================================================================================\n",
      "Moneyness Group  BS Base  BS LGB1  BS LGB2  AHBS Base  AHBS LGB1  AHBS LGB2  CW Base  CW LGB1  CW LGB2\n",
      "          DOTMC 0.127668 0.052823 0.059705   0.122433   0.044123   0.049327 0.113514 0.041652 0.045682\n",
      "           OTMC 0.117841 0.044590 0.050023   0.110103   0.041736   0.046512 0.108715 0.040586 0.045016\n",
      "            ATM 0.115332 0.042872 0.048254   0.110987   0.042921   0.048202 0.108876 0.043254 0.048623\n",
      "           OTMP 0.108485 0.043600 0.048221   0.106252   0.044685   0.049641 0.105232 0.044481 0.049132\n",
      "          DOTMP 0.169017 0.049837 0.057525   0.117603   0.051927   0.058166 0.112094 0.050820 0.056189\n",
      "\n",
      "================================================================================\n",
      "Improvement Percentage by Moneyness Group\n",
      "================================================================================\n",
      "Moneyness Group  BS LGB1  BS LGB2  AHBS LGB1  AHBS LGB2  CW LGB1  CW LGB2\n",
      "          DOTMC   58.62%   53.23%     63.96%     59.71%   63.31%   59.76%\n",
      "           OTMC   62.16%   57.55%     62.09%     57.76%   62.67%   58.59%\n",
      "            ATM   62.83%   58.16%     61.33%     56.57%   60.27%   55.34%\n",
      "           OTMP   59.81%   55.55%     57.94%     53.28%   57.73%   53.31%\n",
      "          DOTMP   70.51%   65.96%     55.85%     50.54%   54.66%   49.87%\n",
      "\n",
      "================================================================================\n",
      "Best Model by Moneyness Group and Error Type\n",
      "================================================================================\n",
      "Moneyness Group Error Type Best Model Base IVRMSE Best IVRMSE Improvement % Other Model  Other IVRMSE  Other Improvement %\n",
      "          DOTMC         BS       LGB1    0.127668    0.052823        58.62%        LGB2      0.059705            53.233784\n",
      "          DOTMC       AHBS       LGB1    0.122433    0.044123        63.96%        LGB2      0.049327            59.711315\n",
      "          DOTMC         CW       LGB1    0.113514    0.041652        63.31%        LGB2      0.045682            59.756905\n",
      "           OTMC         BS       LGB1    0.117841    0.044590        62.16%        LGB2      0.050023            57.550664\n",
      "           OTMC       AHBS       LGB1    0.110103    0.041736        62.09%        LGB2      0.046512            57.756273\n",
      "           OTMC         CW       LGB1    0.108715    0.040586        62.67%        LGB2      0.045016            58.592721\n",
      "            ATM         BS       LGB1    0.115332    0.042872        62.83%        LGB2      0.048254            58.160988\n",
      "            ATM       AHBS       LGB1    0.110987    0.042921        61.33%        LGB2      0.048202            56.569789\n",
      "            ATM         CW       LGB1    0.108876    0.043254        60.27%        LGB2      0.048623            55.341372\n",
      "           OTMP         BS       LGB1    0.108485    0.043600        59.81%        LGB2      0.048221            55.550694\n",
      "           OTMP       AHBS       LGB1    0.106252    0.044685        57.94%        LGB2      0.049641            53.279862\n",
      "           OTMP         CW       LGB1    0.105232    0.044481        57.73%        LGB2      0.049132            53.310560\n",
      "          DOTMP         BS       LGB1    0.169017    0.049837        70.51%        LGB2      0.057525            65.964756\n",
      "          DOTMP       AHBS       LGB1    0.117603    0.051927        55.85%        LGB2      0.058166            50.540839\n",
      "          DOTMP         CW       LGB1    0.112094    0.050820        54.66%        LGB2      0.056189            49.873456\n",
      "\n",
      "================================================================================\n",
      "Summary Statistics\n",
      "================================================================================\n",
      "Overall best model distribution: {'LGB1': np.int64(15)}\n",
      "\n",
      "Average improvement by moneyness group:\n",
      "  OTMC: 62.31%\n",
      "  DOTMC: 61.96%\n",
      "  ATM: 61.48%\n",
      "  DOTMP: 60.34%\n",
      "  OTMP: 58.49%\n",
      "================================================================================\n",
      "IVRMSE by Moneyness Group (Horizon: 5)\n",
      "================================================================================\n",
      "Moneyness Group  BS Base  BS LGB1  BS LGB2  AHBS Base  AHBS LGB1  AHBS LGB2  CW Base  CW LGB1  CW LGB2\n",
      "          DOTMC 0.128018 0.064903 0.069829   0.121936   0.057319   0.060279 0.114775 0.055475 0.057701\n",
      "           OTMC 0.118612 0.054874 0.058557   0.110423   0.051848   0.054864 0.109205 0.050937 0.053719\n",
      "            ATM 0.115928 0.053257 0.056834   0.111427   0.052450   0.055907 0.109983 0.052904 0.056517\n",
      "           OTMP 0.109400 0.054672 0.057731   0.107410   0.054757   0.057984 0.106500 0.054623 0.057670\n",
      "          DOTMP 0.167069 0.064356 0.069202   0.119556   0.066075   0.070306 0.114734 0.065129 0.068797\n",
      "\n",
      "================================================================================\n",
      "Improvement Percentage by Moneyness Group\n",
      "================================================================================\n",
      "Moneyness Group  BS LGB1  BS LGB2  AHBS LGB1  AHBS LGB2  CW LGB1  CW LGB2\n",
      "          DOTMC   49.30%   45.45%     52.99%     50.57%   51.67%   49.73%\n",
      "           OTMC   53.74%   50.63%     53.05%     50.31%   53.36%   50.81%\n",
      "            ATM   54.06%   50.97%     52.93%     49.83%   51.90%   48.61%\n",
      "           OTMP   50.03%   47.23%     49.02%     46.02%   48.71%   45.85%\n",
      "          DOTMP   61.48%   58.58%     44.73%     41.19%   43.23%   40.04%\n",
      "\n",
      "================================================================================\n",
      "Best Model by Moneyness Group and Error Type\n",
      "================================================================================\n",
      "Moneyness Group Error Type Best Model Base IVRMSE Best IVRMSE Improvement % Other Model  Other IVRMSE  Other Improvement %\n",
      "          DOTMC         BS       LGB1    0.128018    0.064903        49.30%        LGB2      0.069829            45.453878\n",
      "          DOTMC       AHBS       LGB1    0.121936    0.057319        52.99%        LGB2      0.060279            50.565101\n",
      "          DOTMC         CW       LGB1    0.114775    0.055475        51.67%        LGB2      0.057701            49.726715\n",
      "           OTMC         BS       LGB1    0.118612    0.054874        53.74%        LGB2      0.058557            50.631428\n",
      "           OTMC       AHBS       LGB1    0.110423    0.051848        53.05%        LGB2      0.054864            50.314825\n",
      "           OTMC         CW       LGB1    0.109205    0.050937        53.36%        LGB2      0.053719            50.808751\n",
      "            ATM         BS       LGB1    0.115928    0.053257        54.06%        LGB2      0.056834            50.974826\n",
      "            ATM       AHBS       LGB1    0.111427    0.052450        52.93%        LGB2      0.055907            49.826513\n",
      "            ATM         CW       LGB1    0.109983    0.052904        51.90%        LGB2      0.056517            48.612935\n",
      "           OTMP         BS       LGB1    0.109400    0.054672        50.03%        LGB2      0.057731            47.229792\n",
      "           OTMP       AHBS       LGB1    0.107410    0.054757        49.02%        LGB2      0.057984            46.016659\n",
      "           OTMP         CW       LGB1    0.106500    0.054623        48.71%        LGB2      0.057670            45.849614\n",
      "          DOTMP         BS       LGB1    0.167069    0.064356        61.48%        LGB2      0.069202            58.579023\n",
      "          DOTMP       AHBS       LGB1    0.119556    0.066075        44.73%        LGB2      0.070306            41.194048\n",
      "          DOTMP         CW       LGB1    0.114734    0.065129        43.23%        LGB2      0.068797            40.037716\n",
      "\n",
      "================================================================================\n",
      "Summary Statistics\n",
      "================================================================================\n",
      "Overall best model distribution: {'LGB1': np.int64(15)}\n",
      "\n",
      "Average improvement by moneyness group:\n",
      "  OTMC: 53.38%\n",
      "  ATM: 52.96%\n",
      "  DOTMC: 51.32%\n",
      "  DOTMP: 49.81%\n",
      "  OTMP: 49.25%\n",
      "================================================================================\n",
      "IVRMSE by Moneyness Group (Horizon: 21)\n",
      "================================================================================\n",
      "Moneyness Group  BS Base  BS LGB1  BS LGB2  AHBS Base  AHBS LGB1  AHBS LGB2  CW Base  CW LGB1  CW LGB2\n",
      "          DOTMC 0.131736 0.084775 0.088247   0.122920   0.077189   0.078806 0.118994 0.075049 0.076566\n",
      "           OTMC 0.121774 0.074174 0.076596   0.112419   0.070602   0.072478 0.111955 0.070671 0.072306\n",
      "            ATM 0.118978 0.073407 0.076247   0.114232   0.071595   0.074171 0.114213 0.073308 0.075833\n",
      "           OTMP 0.114142 0.074546 0.077100   0.112581   0.073597   0.075873 0.111849 0.074481 0.076363\n",
      "          DOTMP 0.164479 0.087325 0.090083   0.124984   0.086997   0.089331 0.120167 0.085294 0.087111\n",
      "\n",
      "================================================================================\n",
      "Improvement Percentage by Moneyness Group\n",
      "================================================================================\n",
      "Moneyness Group  BS LGB1  BS LGB2  AHBS LGB1  AHBS LGB2  CW LGB1  CW LGB2\n",
      "          DOTMC   35.65%   33.01%     37.20%     35.89%   36.93%   35.66%\n",
      "           OTMC   39.09%   37.10%     37.20%     35.53%   36.88%   35.42%\n",
      "            ATM   38.30%   35.91%     37.32%     35.07%   35.81%   33.60%\n",
      "           OTMP   34.69%   32.45%     34.63%     32.61%   33.41%   31.73%\n",
      "          DOTMP   46.91%   45.23%     30.39%     28.53%   29.02%   27.51%\n",
      "\n",
      "================================================================================\n",
      "Best Model by Moneyness Group and Error Type\n",
      "================================================================================\n",
      "Moneyness Group Error Type Best Model Base IVRMSE Best IVRMSE Improvement % Other Model  Other IVRMSE  Other Improvement %\n",
      "          DOTMC         BS       LGB1    0.131736    0.084775        35.65%        LGB2      0.088247            33.012474\n",
      "          DOTMC       AHBS       LGB1    0.122920    0.077189        37.20%        LGB2      0.078806            35.888195\n",
      "          DOTMC         CW       LGB1    0.118994    0.075049        36.93%        LGB2      0.076566            35.655611\n",
      "           OTMC         BS       LGB1    0.121774    0.074174        39.09%        LGB2      0.076596            37.100329\n",
      "           OTMC       AHBS       LGB1    0.112419    0.070602        37.20%        LGB2      0.072478            35.528346\n",
      "           OTMC         CW       LGB1    0.111955    0.070671        36.88%        LGB2      0.072306            35.415519\n",
      "            ATM         BS       LGB1    0.118978    0.073407        38.30%        LGB2      0.076247            35.914734\n",
      "            ATM       AHBS       LGB1    0.114232    0.071595        37.32%        LGB2      0.074171            35.069342\n",
      "            ATM         CW       LGB1    0.114213    0.073308        35.81%        LGB2      0.075833            33.603454\n",
      "           OTMP         BS       LGB1    0.114142    0.074546        34.69%        LGB2      0.077100            32.452741\n",
      "           OTMP       AHBS       LGB1    0.112581    0.073597        34.63%        LGB2      0.075873            32.605509\n",
      "           OTMP         CW       LGB1    0.111849    0.074481        33.41%        LGB2      0.076363            31.726799\n",
      "          DOTMP         BS       LGB1    0.164479    0.087325        46.91%        LGB2      0.090083            45.231533\n",
      "          DOTMP       AHBS       LGB1    0.124984    0.086997        30.39%        LGB2      0.089331            28.525763\n",
      "          DOTMP         CW       LGB1    0.120167    0.085294        29.02%        LGB2      0.087111            27.508867\n",
      "\n",
      "================================================================================\n",
      "Summary Statistics\n",
      "================================================================================\n",
      "Overall best model distribution: {'LGB1': np.int64(15)}\n",
      "\n",
      "Average improvement by moneyness group:\n",
      "  OTMC: 37.72%\n",
      "  ATM: 37.14%\n",
      "  DOTMC: 36.59%\n",
      "  DOTMP: 35.44%\n",
      "  OTMP: 34.24%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the moneyness groups\n",
    "moneyness_groups = ['DOTMC', 'OTMC', 'ATM', 'OTMP', 'DOTMP']\n",
    "\n",
    "def analyze_ivrmse_by_moneyness(test_data):\n",
    "\n",
    "    # 1. Group the test data by moneyness\n",
    "    results = {}\n",
    "    for group in moneyness_groups:\n",
    "        group_data = test_data[test_data['moneyness_category'] == group]\n",
    "        \n",
    "        # Skip if no data in this group\n",
    "        if len(group_data) == 0:\n",
    "            print(f\"Warning: No data found for moneyness group {group}\")\n",
    "            continue\n",
    "            \n",
    "        # Initialize results for this group\n",
    "        results[group] = {}\n",
    "        \n",
    "        # 2. Calculate IVRMSE for each error type and model\n",
    "        for error_type in ['bs', 'ahbs', 'cw']:\n",
    "            # Column names\n",
    "            orig_col = f'iv_{error_type}'\n",
    "            \n",
    "            # Skip if column doesn't exist\n",
    "            if orig_col not in group_data.columns:\n",
    "                print(f\"Warning: Column {orig_col} not found, skipping...\")\n",
    "                continue\n",
    "                \n",
    "            # Calculate baseline IVRMSE\n",
    "            base_rmse = np.sqrt(mean_squared_error(\n",
    "                group_data['impl_volatility'], \n",
    "                group_data[orig_col]\n",
    "            ))\n",
    "            \n",
    "            # Store baseline IVRMSE\n",
    "            results[group][f\"{error_type}_base\"] = base_rmse\n",
    "            \n",
    "            # Calculate corrected IVRMSE for each model\n",
    "            for model in ['LGB1', 'LGB2']:\n",
    "                corrected_col = f'iv_{error_type}_corrected_{model}'\n",
    "                \n",
    "                # Skip if column doesn't exist\n",
    "                if corrected_col not in group_data.columns:\n",
    "                    print(f\"Warning: Column {corrected_col} not found, skipping...\")\n",
    "                    continue\n",
    "                    \n",
    "                corrected_rmse = np.sqrt(mean_squared_error(\n",
    "                    group_data['impl_volatility'], \n",
    "                    group_data[corrected_col]\n",
    "                ))\n",
    "                \n",
    "                # Calculate improvement percentage\n",
    "                improvement = (base_rmse - corrected_rmse) / base_rmse * 100\n",
    "                \n",
    "                # Store results\n",
    "                results[group][f\"{error_type}_{model}\"] = corrected_rmse\n",
    "                results[group][f\"{error_type}_{model}_improvement\"] = improvement\n",
    "    \n",
    "    return results\n",
    "\n",
    "def format_results_table(results):\n",
    "\n",
    "    # Prepare IVRMSE table data\n",
    "    ivrmse_data = []\n",
    "    for group, group_results in results.items():\n",
    "        row = {'Moneyness Group': group}\n",
    "        \n",
    "        for key, value in group_results.items():\n",
    "            if not key.endswith('improvement'):\n",
    "                if key.endswith('base'):\n",
    "                    # Format baseline columns\n",
    "                    error_type = key.split('_')[0].upper()\n",
    "                    row[f\"{error_type} Base\"] = value\n",
    "                else:\n",
    "                    # Format model columns\n",
    "                    parts = key.split('_')\n",
    "                    error_type = parts[0].upper()\n",
    "                    model = parts[1]\n",
    "                    row[f\"{error_type} {model}\"] = value\n",
    "        \n",
    "        ivrmse_data.append(row)\n",
    "    \n",
    "    # Prepare improvement percentage table data\n",
    "    improvement_data = []\n",
    "    for group, group_results in results.items():\n",
    "        row = {'Moneyness Group': group}\n",
    "        \n",
    "        for key, value in group_results.items():\n",
    "            if key.endswith('improvement'):\n",
    "                # Format improvement columns\n",
    "                parts = key.replace('_improvement', '').split('_')\n",
    "                error_type = parts[0].upper()\n",
    "                model = parts[1]\n",
    "                row[f\"{error_type} {model}\"] = value\n",
    "        \n",
    "        improvement_data.append(row)\n",
    "    \n",
    "    # Create DataFrames\n",
    "    ivrmse_df = pd.DataFrame(ivrmse_data)\n",
    "    improvement_df = pd.DataFrame(improvement_data)\n",
    "    \n",
    "    # Sort columns for better readability\n",
    "    ivrmse_cols = ['Moneyness Group']\n",
    "    improvement_cols = ['Moneyness Group']\n",
    "    \n",
    "    for et in ['BS', 'AHBS', 'CW']:\n",
    "        ivrmse_cols.extend([f\"{et} Base\", f\"{et} LGB1\", f\"{et} LGB2\"])\n",
    "        improvement_cols.extend([f\"{et} LGB1\", f\"{et} LGB2\"])\n",
    "    \n",
    "    # Reorder columns if they exist\n",
    "    ivrmse_df = ivrmse_df[[col for col in ivrmse_cols if col in ivrmse_df.columns]]\n",
    "    improvement_df = improvement_df[[col for col in improvement_cols if col in improvement_df.columns]]\n",
    "    \n",
    "    return ivrmse_df, improvement_df\n",
    "\n",
    "def find_best_models(results):\n",
    "\n",
    "    best_models = []\n",
    "    \n",
    "    for group, group_results in results.items():\n",
    "        for error_type in ['bs', 'ahbs', 'cw']:\n",
    "            # Get baseline IVRMSE\n",
    "            base_key = f\"{error_type}_base\"\n",
    "            if base_key not in group_results:\n",
    "                continue\n",
    "                \n",
    "            base_rmse = group_results[base_key]\n",
    "            \n",
    "            # Find best model for this error type\n",
    "            models = [m for m in ['LGB1', 'LGB2'] if f\"{error_type}_{m}\" in group_results]\n",
    "            if not models:\n",
    "                continue\n",
    "            \n",
    "            # Find model with lowest IVRMSE    \n",
    "            best_model = min(models, key=lambda m: group_results[f\"{error_type}_{m}\"])\n",
    "            best_rmse = group_results[f\"{error_type}_{best_model}\"]\n",
    "            improvement = group_results[f\"{error_type}_{best_model}_improvement\"]\n",
    "            \n",
    "            # Also get the values for the other model for comparison\n",
    "            other_models = [m for m in models if m != best_model]\n",
    "            other_model_data = {}\n",
    "            if other_models:\n",
    "                other_model = other_models[0]\n",
    "                other_rmse = group_results[f\"{error_type}_{other_model}\"]\n",
    "                other_improvement = group_results[f\"{error_type}_{other_model}_improvement\"]\n",
    "                other_model_data = {\n",
    "                    f'Other Model': other_model,\n",
    "                    f'Other IVRMSE': other_rmse,\n",
    "                    f'Other Improvement %': other_improvement\n",
    "                }\n",
    "            \n",
    "            model_data = {\n",
    "                'Moneyness Group': group,\n",
    "                'Error Type': error_type.upper(),\n",
    "                'Best Model': best_model,\n",
    "                'Base IVRMSE': base_rmse,\n",
    "                'Best IVRMSE': best_rmse,\n",
    "                'Improvement %': improvement\n",
    "            }\n",
    "            \n",
    "            # Add other model data if available\n",
    "            model_data.update(other_model_data)\n",
    "            \n",
    "            best_models.append(model_data)\n",
    "    \n",
    "    return pd.DataFrame(best_models)\n",
    "\n",
    "def print_formatted_tables(results, horizon):\n",
    "    \"\"\"\n",
    "    Print formatted tables from the analysis results.\n",
    "    Parameters:\n",
    "      results (dict): Results from analyze_ivrmse_by_moneyness function\n",
    "      horizon (int): De prediction horizon (bv. 1, 5 of 21)\n",
    "    \"\"\"\n",
    "    # Format results into DataFrames\n",
    "    ivrmse_df, improvement_df = format_results_table(results)\n",
    "\n",
    "    # Format IVRMSE table\n",
    "    pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"IVRMSE by Moneyness Group (Horizon: {horizon})\")\n",
    "    print(\"=\" * 80)\n",
    "    print(ivrmse_df.to_string(index=False))\n",
    "    \n",
    "    # Format improvement table\n",
    "    pd.set_option('display.float_format', '{:.2f}%'.format)\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Improvement Percentage by Moneyness Group\")\n",
    "    print(\"=\" * 80)\n",
    "    print(improvement_df.to_string(index=False))\n",
    "    \n",
    "    # Find best models\n",
    "    best_models_df = find_best_models(results)\n",
    "    \n",
    "    # Reset float format for mixed table\n",
    "    pd.set_option('display.float_format', None)\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Best Model by Moneyness Group and Error Type\")\n",
    "    print(\"=\" * 80)\n",
    "    # Format specific columns\n",
    "    best_models_df['Base IVRMSE'] = best_models_df['Base IVRMSE'].map('{:.6f}'.format)\n",
    "    best_models_df['Best IVRMSE'] = best_models_df['Best IVRMSE'].map('{:.6f}'.format)\n",
    "    best_models_df['Improvement %'] = best_models_df['Improvement %'].map('{:.2f}%'.format)\n",
    "    print(best_models_df.to_string(index=False))\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Summary Statistics\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Count best model occurrences\n",
    "    model_counts = best_models_df['Best Model'].value_counts()\n",
    "    print(f\"Overall best model distribution: {dict(model_counts)}\")\n",
    "    \n",
    "    # Average improvement by moneyness group\n",
    "    print(\"\\nAverage improvement by moneyness group:\")\n",
    "    # Convert percentage strings to numeric values\n",
    "    best_models_df['Improvement_Numeric'] = pd.to_numeric(best_models_df['Improvement %'].str.rstrip('%'))\n",
    "    \n",
    "    # Group and calculate means\n",
    "    avg_improvement = best_models_df.groupby('Moneyness Group')['Improvement_Numeric'].mean()\n",
    "    \n",
    "    # Handle the case where there's only one group (which returns a scalar)\n",
    "    if isinstance(avg_improvement, pd.Series):\n",
    "        # Sort if it's a Series with multiple values\n",
    "        sorted_improvements = avg_improvement.sort_values(ascending=False)\n",
    "        for group, imp in sorted_improvements.items():\n",
    "            print(f\"  {group}: {imp:.2f}%\")\n",
    "    else:\n",
    "        # Just print the single value if it's a scalar\n",
    "        group = best_models_df['Moneyness Group'].iloc[0]\n",
    "        print(f\"  {group}: {avg_improvement:.2f}%\")\n",
    "    \n",
    "    # Save results to CSV files\n",
    "    ivrmse_df.to_csv('ivrmse_by_moneyness_lightgbm.csv', index=False)\n",
    "    improvement_df.to_csv('improvement_by_moneyness_lightgbm.csv', index=False)\n",
    "    best_models_df.to_csv('best_models_by_moneyness_lightgbm.csv', index=False)\n",
    "\n",
    "all_results = {\n",
    "    1: analyze_ivrmse_by_moneyness(option_only_data[1]),\n",
    "    5: analyze_ivrmse_by_moneyness(option_only_data[5]),\n",
    "    21: analyze_ivrmse_by_moneyness(option_only_data[21])\n",
    "}\n",
    "\n",
    "for h, res in all_results.items():\n",
    "    print_formatted_tables(res, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c790c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_lightgbm_importance(model, feature_names, importance_type='gain', model_name=\"LightGBM\"):\n",
    "\n",
    "    importance_values = model.feature_importance(importance_type=importance_type)\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importance_values\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "\n",
    "    print(f\"\\nTop 20 features by {importance_type} for {model_name}:\")\n",
    "    print(importance_df.head(20))\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "def plot_feature_importance(importance_df, model_name=\"LightGBM\", top_n=30):\n",
    "    \"\"\"\n",
    "    Plot the top N feature importances.\n",
    "    \"\"\"\n",
    "    plot_data = importance_df.head(top_n)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.barh(np.arange(len(plot_data)), plot_data['Importance'], align='center')\n",
    "    plt.yticks(np.arange(len(plot_data)), plot_data['Feature'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title(f'Top {top_n} Features - {model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.gca().invert_yaxis()\n",
    "    return plt.gcf()\n",
    "\n",
    "def plot_split_vs_gain(split_df, gain_df, top_n=30, model_name=\"LightGBM\"):\n",
    "    \"\"\"\n",
    "    Plot Split vs Gain comparison for top N features.\n",
    "    \"\"\"\n",
    "    merged_df = pd.merge(split_df, gain_df, on='Feature', suffixes=('_split', '_gain'))\n",
    "    merged_df = merged_df.head(top_n)\n",
    "\n",
    "    x = np.arange(len(merged_df))\n",
    "    width = 0.35\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(x - width/2, merged_df['Importance_split'], width, label='Split')\n",
    "    plt.bar(x + width/2, merged_df['Importance_gain'], width, label='Gain')\n",
    "\n",
    "    plt.xticks(x, merged_df['Feature'], rotation=90)\n",
    "    plt.ylabel('Importance')\n",
    "    plt.title(f'Split vs Gain Importance - {model_name}')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.gca().invert_yaxis()\n",
    "    return plt.gcf()\n",
    "\n",
    "def calculate_permutation_importance(model, X, y, feature_names, n_repeats=10, random_state=42):\n",
    "\n",
    "    def predict_fn(X_data):\n",
    "        return model.predict(X_data)\n",
    "\n",
    "    r = sklearn_permutation_importance(predict_fn, X, y, n_repeats=n_repeats, random_state=random_state)\n",
    "    perm_importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': r.importances_mean,\n",
    "        'Std': r.importances_std\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a3f596",
   "metadata": {},
   "source": [
    "Permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0a6f2ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = option_only_data[1].sample(n=100000, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc69fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing bs LGB1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def manual_permutation_importance(model, X: np.ndarray, y: np.ndarray,\n",
    "                                  feature_names: list[str],\n",
    "                                  n_repeats: int = 10,\n",
    "                                  random_state: int = 42) -> pd.Series:\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    baseline_preds = model.predict(X, verbose=0).flatten()\n",
    "    baseline_score = mean_squared_error(y, baseline_preds)\n",
    "\n",
    "    importances = []\n",
    "    for idx, col in enumerate(feature_names):\n",
    "        scores = []\n",
    "        for _ in range(n_repeats):\n",
    "            X_permuted = X.copy()\n",
    "            X_permuted[:, idx] = rng.permutation(X_permuted[:, idx])\n",
    "            permuted_preds = model.predict(X_permuted, verbose=0).flatten()\n",
    "            score = mean_squared_error(y, permuted_preds)\n",
    "            scores.append(score - baseline_score)\n",
    "        importances.append(np.mean(scores))\n",
    "\n",
    "    return pd.Series(importances, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "def plot_importance(importance: pd.Series, top_n: int = 20, title: str = \"Feature Importance\"):\n",
    "    data = importance.head(top_n).sort_values()\n",
    "    plt.figure(figsize=(8, max(4, 0.2 * top_n)))\n",
    "    data.plot.barh()\n",
    "    plt.xlabel('Importance (Increase in MSE)')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "X_test_scaled, y_test_dict, _, _ = prepare_data(sample_df, save_paths=False)\n",
    "\n",
    "# Load feature columns\n",
    "feature_columns = joblib.load(r'C:\\Users\\maxva\\OneDrive - Tilburg University\\Msc. Data Science\\Master Thesis\\Code\\Models\\LigthGBM Forecast\\Option only\\LightGBM forecast option_h1\\feature_columns.pkl')\n",
    "\n",
    "# Safely access only BS -> LGB1\n",
    "error_type = 'bs'\n",
    "model_name = 'LGB1'\n",
    "\n",
    "# Get the model\n",
    "model = loaded_models.get(error_type, {}).get(model_name, None)\n",
    "\n",
    "if model is None:\n",
    "    print(f\"Skipping {error_type} {model_name}: model not loaded\")\n",
    "else:\n",
    "    print(f\"Processing {error_type} {model_name}\")\n",
    "\n",
    "    # Select the correct y target\n",
    "    y_test = y_test_dict[error_type]\n",
    "\n",
    "    # Compute permutation importance\n",
    "    imp_perm = manual_permutation_importance(model, X_test_scaled.values, y_test.values, feature_columns)\n",
    "\n",
    "    # Plot the results\n",
    "    title = f\"{error_type.upper()} {model_name} Option Only\"\n",
    "    plot_importance(imp_perm, top_n=20, title=title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
