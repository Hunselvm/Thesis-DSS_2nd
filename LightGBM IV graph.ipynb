{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e9b7fe",
   "metadata": {},
   "source": [
    "LightGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32fa0f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered Option-only data for horizon 1 on 2020-10-10:\n",
      "Shape: (1281, 176)\n",
      "                                   ID     iv_cw        date  cp_flag  \\\n",
      "990379  2020-05-01_AAPL 200529C292500  0.450584  2020-05-01        1   \n",
      "990380  2020-05-01_AAPL 200529C295000  0.447356  2020-05-01        1   \n",
      "990381  2020-05-01_AAPL 200529C297500  0.444564  2020-05-01        1   \n",
      "990382  2020-05-01_AAPL 200529C300000  0.442207  2020-05-01        1   \n",
      "990383  2020-05-01_AAPL 200529C305000  0.438777  2020-05-01        1   \n",
      "\n",
      "        option_price  stock_price  moneyness  time_to_expiry  strike_price  \\\n",
      "990379         8.425      292.425   0.999744              27         292.5   \n",
      "990380         7.225      292.425   0.991271              27         295.0   \n",
      "990381         6.200      292.425   0.982941              27         297.5   \n",
      "990382         5.275      292.425   0.974750              27         300.0   \n",
      "990383         3.625      292.425   0.958770              27         305.0   \n",
      "\n",
      "        volume  ...   iv_ahbs     iv_bs  prediction_horizon  train_date  \\\n",
      "990379     276  ...  0.466143  0.466571                 h=1  2020-05-01   \n",
      "990380     526  ...  0.463298  0.466571                 h=1  2020-05-01   \n",
      "990381     449  ...  0.460615  0.466571                 h=1  2020-05-01   \n",
      "990382    1213  ...  0.458089  0.466571                 h=1  2020-05-01   \n",
      "990383     267  ...  0.453477  0.466571                 h=1  2020-05-01   \n",
      "\n",
      "         test_date                         new_id  impl_volatility  \\\n",
      "990379  2020-05-04  2020-05-04_AAPL 200529C292500         0.333655   \n",
      "990380  2020-05-04  2020-05-04_AAPL 200529C295000         0.328039   \n",
      "990381  2020-05-04  2020-05-04_AAPL 200529C297500         0.320756   \n",
      "990382  2020-05-04  2020-05-04_AAPL 200529C300000         0.316741   \n",
      "990383  2020-05-04  2020-05-04_AAPL 200529C305000         0.304980   \n",
      "\n",
      "        iv_bs_error  iv_ahbs_error  iv_cw_error  \n",
      "990379    -0.132916      -0.132488    -0.116929  \n",
      "990380    -0.138532      -0.135259    -0.119317  \n",
      "990381    -0.145815      -0.139859    -0.123808  \n",
      "990382    -0.149830      -0.141348    -0.125466  \n",
      "990383    -0.161591      -0.148497    -0.133797  \n",
      "\n",
      "[5 rows x 176 columns]\n",
      "\n",
      "Filtered Option-only data for horizon 5 on 2020-10-10:\n",
      "Shape: (1281, 176)\n",
      "                                   ID     iv_cw        date  cp_flag  \\\n",
      "990379  2020-05-01_AAPL 200529C292500  0.450584  2020-05-01        1   \n",
      "990380  2020-05-01_AAPL 200529C295000  0.447356  2020-05-01        1   \n",
      "990381  2020-05-01_AAPL 200529C297500  0.444564  2020-05-01        1   \n",
      "990382  2020-05-01_AAPL 200529C300000  0.442207  2020-05-01        1   \n",
      "990383  2020-05-01_AAPL 200529C305000  0.438777  2020-05-01        1   \n",
      "\n",
      "        option_price  stock_price  moneyness  time_to_expiry  strike_price  \\\n",
      "990379         8.425      292.425   0.999744              27         292.5   \n",
      "990380         7.225      292.425   0.991271              27         295.0   \n",
      "990381         6.200      292.425   0.982941              27         297.5   \n",
      "990382         5.275      292.425   0.974750              27         300.0   \n",
      "990383         3.625      292.425   0.958770              27         305.0   \n",
      "\n",
      "        volume  ...   iv_ahbs     iv_bs  prediction_horizon  train_date  \\\n",
      "990379     276  ...  0.466143  0.466571                 h=1  2020-05-01   \n",
      "990380     526  ...  0.463298  0.466571                 h=1  2020-05-01   \n",
      "990381     449  ...  0.460615  0.466571                 h=1  2020-05-01   \n",
      "990382    1213  ...  0.458089  0.466571                 h=1  2020-05-01   \n",
      "990383     267  ...  0.453477  0.466571                 h=1  2020-05-01   \n",
      "\n",
      "         test_date                         new_id  impl_volatility  \\\n",
      "990379  2020-05-04  2020-05-04_AAPL 200529C292500         0.333655   \n",
      "990380  2020-05-04  2020-05-04_AAPL 200529C295000         0.328039   \n",
      "990381  2020-05-04  2020-05-04_AAPL 200529C297500         0.320756   \n",
      "990382  2020-05-04  2020-05-04_AAPL 200529C300000         0.316741   \n",
      "990383  2020-05-04  2020-05-04_AAPL 200529C305000         0.304980   \n",
      "\n",
      "        iv_bs_error  iv_ahbs_error  iv_cw_error  \n",
      "990379    -0.132916      -0.132488    -0.116929  \n",
      "990380    -0.138532      -0.135259    -0.119317  \n",
      "990381    -0.145815      -0.139859    -0.123808  \n",
      "990382    -0.149830      -0.141348    -0.125466  \n",
      "990383    -0.161591      -0.148497    -0.133797  \n",
      "\n",
      "[5 rows x 176 columns]\n",
      "\n",
      "Filtered Option-only data for horizon 21 on 2020-10-10:\n",
      "Shape: (1281, 176)\n",
      "                                   ID     iv_cw        date  cp_flag  \\\n",
      "990379  2020-05-01_AAPL 200529C292500  0.450584  2020-05-01        1   \n",
      "990380  2020-05-01_AAPL 200529C295000  0.447356  2020-05-01        1   \n",
      "990381  2020-05-01_AAPL 200529C297500  0.444564  2020-05-01        1   \n",
      "990382  2020-05-01_AAPL 200529C300000  0.442207  2020-05-01        1   \n",
      "990383  2020-05-01_AAPL 200529C305000  0.438777  2020-05-01        1   \n",
      "\n",
      "        option_price  stock_price  moneyness  time_to_expiry  strike_price  \\\n",
      "990379         8.425      292.425   0.999744              27         292.5   \n",
      "990380         7.225      292.425   0.991271              27         295.0   \n",
      "990381         6.200      292.425   0.982941              27         297.5   \n",
      "990382         5.275      292.425   0.974750              27         300.0   \n",
      "990383         3.625      292.425   0.958770              27         305.0   \n",
      "\n",
      "        volume  ...   iv_ahbs     iv_bs  prediction_horizon  train_date  \\\n",
      "990379     276  ...  0.466143  0.466571                 h=1  2020-05-01   \n",
      "990380     526  ...  0.463298  0.466571                 h=1  2020-05-01   \n",
      "990381     449  ...  0.460615  0.466571                 h=1  2020-05-01   \n",
      "990382    1213  ...  0.458089  0.466571                 h=1  2020-05-01   \n",
      "990383     267  ...  0.453477  0.466571                 h=1  2020-05-01   \n",
      "\n",
      "         test_date                         new_id  impl_volatility  \\\n",
      "990379  2020-05-04  2020-05-04_AAPL 200529C292500         0.333655   \n",
      "990380  2020-05-04  2020-05-04_AAPL 200529C295000         0.328039   \n",
      "990381  2020-05-04  2020-05-04_AAPL 200529C297500         0.320756   \n",
      "990382  2020-05-04  2020-05-04_AAPL 200529C300000         0.316741   \n",
      "990383  2020-05-04  2020-05-04_AAPL 200529C305000         0.304980   \n",
      "\n",
      "        iv_bs_error  iv_ahbs_error  iv_cw_error  \n",
      "990379    -0.132916      -0.132488    -0.116929  \n",
      "990380    -0.138532      -0.135259    -0.119317  \n",
      "990381    -0.145815      -0.139859    -0.123808  \n",
      "990382    -0.149830      -0.141348    -0.125466  \n",
      "990383    -0.161591      -0.148497    -0.133797  \n",
      "\n",
      "[5 rows x 176 columns]\n",
      "\n",
      "Train data shape: (2669654, 166)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "# Create a dictionary to store data for each horizon\n",
    "test_data = {}\n",
    "horizons = [1, 5, 21]\n",
    "\n",
    "# Load and filter test data for each horizon on date '2020-10-10'\n",
    "for horizon in horizons:\n",
    "    file_path = f'C:/Users/maxva/OneDrive - Tilburg University/Msc. Data Science/Master Thesis/Data/merged_results_h{horizon}.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Filter to 2020-10-10 only\n",
    "    df = df[df['date'] == '2020-05-01']\n",
    "\n",
    "    # Select option-only columns\n",
    "    option_columns = [\n",
    "        'cp_flag',\n",
    "        'stock_price',\n",
    "        'moneyness',\n",
    "        'time_to_expiry',\n",
    "        'strike_price',\n",
    "        'rf',\n",
    "        'delta',\n",
    "        'gamma',\n",
    "        'vega',\n",
    "        'theta',\n",
    "        'iv_ahbs',\n",
    "        'iv_ahbs_error',\n",
    "        'iv_bs',\n",
    "        'iv_bs_error',\n",
    "        'iv_cw',\n",
    "        'iv_cw_error',\n",
    "        'impl_volatility'\n",
    "    ]\n",
    "\n",
    "    # Store in dictionary\n",
    "    test_data[horizon] = df\n",
    "\n",
    "    # Confirm the result\n",
    "    print(f\"\\nFiltered Option-only data for horizon {horizon} on 2020-10-10:\")\n",
    "    print(f\"Shape: {test_data[1].shape}\")\n",
    "    print(test_data[1].head())\n",
    "\n",
    "# If you want to load your train data as well (not filtered by date)\n",
    "train_data = pd.read_csv('C:/Users/maxva/OneDrive - Tilburg University/Msc. Data Science/Master Thesis/Data/merged_results_train.csv')\n",
    "train_data = train_data.drop(columns=['date', 'moneyness_category'], errors='ignore')\n",
    "print(f\"\\nTrain data shape: {train_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d70c24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# PART 1: LIGHTGBM MODEL DEFINITION\n",
    "###########################################\n",
    "\n",
    "def create_lgb_model(model_type):\n",
    "    \"\"\"\n",
    "    Create LightGBM models with configurations based on model type.\n",
    "    \n",
    "    Parameters:\n",
    "    model_type (str): One of 'LGB1' or 'LGB2', specifying which configuration to use\n",
    "    \n",
    "    Returns:\n",
    "    model: LightGBM model with specified parameters\n",
    "    \"\"\"\n",
    "    if model_type == 'LGB1':\n",
    "        # Standard LightGBM configuration\n",
    "        params = {\n",
    "            'objective': 'regression',\n",
    "            'metric': 'mse',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': -1\n",
    "        }\n",
    "    \n",
    "    elif model_type == 'LGB2':\n",
    "        # More complex LightGBM configuration with different hyperparameters\n",
    "        params = {\n",
    "            'objective': 'regression',\n",
    "            'metric': 'mse',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 63,\n",
    "            'learning_rate': 0.01,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.7,\n",
    "            'bagging_freq': 4,\n",
    "            'min_data_in_leaf': 20,\n",
    "            'max_depth': 10,\n",
    "            'verbose': -1\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type. Choose from 'LGB1' or 'LGB2'.\")\n",
    "    \n",
    "    return params\n",
    "\n",
    "def train_and_evaluate_model(params, X_train, y_train, X_test, y_test, num_boost_round=100):\n",
    "    \"\"\"\n",
    "    Train and evaluate a LightGBM model.\n",
    "    \n",
    "    Parameters:\n",
    "    params: LightGBM parameters dictionary\n",
    "    X_train: Training features\n",
    "    y_train: Training target values\n",
    "    X_test: Test features\n",
    "    y_test: Test target values\n",
    "    num_boost_round: Number of boosting iterations\n",
    "    \n",
    "    Returns:\n",
    "    model: Trained LightGBM model\n",
    "    mse: Mean squared error on test data\n",
    "    \"\"\"\n",
    "    # Create LightGBM datasets\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "    \n",
    "    # Train model with early stopping\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=num_boost_round,\n",
    "        valid_sets=[valid_data],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=20, verbose=True)]\n",
    "    )\n",
    "    \n",
    "    # Evaluate model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    return model, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66054835",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# PART 2: DATA PREPARATION\n",
    "###########################################\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def prepare_data(option_only: pd.DataFrame, save_paths: bool = True):\n",
    "    \"\"\"\n",
    "    Prepare features and target variables, split data, scale features, and optionally save scaler and feature list.\n",
    "    Handles three target variables: iv_bs_error, iv_ahbs_error, iv_cw_error.\n",
    "\n",
    "    Parameters:\n",
    "    option_only (pd.DataFrame): Input DataFrame containing option data.\n",
    "    save_paths (bool): Whether to persist scaler and feature_columns to disk.\n",
    "\n",
    "    Returns:\n",
    "    tuple: (\n",
    "        X_train_scaled (pd.DataFrame),\n",
    "        X_test_scaled (pd.DataFrame),\n",
    "        y_train_dict (dict),\n",
    "        y_test_dict (dict),\n",
    "        scaler (StandardScaler),\n",
    "        feature_columns (list)\n",
    "    )\n",
    "    \"\"\"\n",
    "    # 1) Define features and targets\n",
    "    exclude_cols = [\n",
    "        'iv_bs_error', 'iv_ahbs', 'iv_ahbs_error',\n",
    "        'iv_bs', 'iv_cw', 'iv_cw_error',\n",
    "        'impl_volatility'\n",
    "    ]\n",
    "    feature_columns = [col for col in option_only.columns if col not in exclude_cols]\n",
    "    X = option_only[feature_columns]\n",
    "    y_train_dict = {\n",
    "        'bs': option_only['iv_bs_error'],\n",
    "        'ahbs': option_only['iv_ahbs_error'],\n",
    "        'cw': option_only['iv_cw_error']\n",
    "    }\n",
    "    y_test_dict = y_train_dict.copy()\n",
    "\n",
    "    # 2) One consistent train/test split by index\n",
    "    train_idx, test_idx = train_test_split(\n",
    "        option_only.index, test_size=0.2, random_state=42\n",
    "    )\n",
    "    X_train = X.loc[train_idx]\n",
    "    X_test = X.loc[test_idx]\n",
    "    y_train_dict = {k: v.loc[train_idx] for k, v in y_train_dict.items()}\n",
    "    y_test_dict  = {k: v.loc[test_idx]  for k, v in y_test_dict.items()}\n",
    "\n",
    "    # 3) Scale features\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train_scaled = pd.DataFrame(\n",
    "        scaler.transform(X_train),\n",
    "        columns=feature_columns,\n",
    "        index=train_idx\n",
    "    )\n",
    "    X_test_scaled = pd.DataFrame(\n",
    "        scaler.transform(X_test),\n",
    "        columns=feature_columns,\n",
    "        index=test_idx\n",
    "    )\n",
    "\n",
    "    # 4) Persist scaler and feature list for later use\n",
    "    if save_paths:\n",
    "        joblib.dump(scaler, 'scaler.pkl')\n",
    "        joblib.dump(feature_columns, 'feature_columns.pkl')\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train_dict, y_test_dict, scaler, feature_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a205ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# PART 3: PREDICTION FUNCTION\n",
    "###########################################\n",
    "\n",
    "def predict_and_add_to_test_data(models, test_data, scaler, feature_columns, error_type):\n",
    "    \"\"\"\n",
    "    Prepare test data, generate predictions and add them to the test dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    models (dict): Dictionary containing trained models with keys as model names\n",
    "    test_data (pandas.DataFrame): Test dataset to make predictions on\n",
    "    scaler (StandardScaler): Fitted scaler to transform the test features\n",
    "    feature_columns (list): List of column names to use as features\n",
    "    error_type (str): Type of error being predicted ('bs', 'ahbs', or 'cw')\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Test dataset with added prediction columns\n",
    "    \"\"\"\n",
    "    # Create a copy of the test data to avoid modifying the original\n",
    "    result_df = test_data.copy()\n",
    "    \n",
    "    # Extract features from test data\n",
    "    X_test = test_data[feature_columns]\n",
    "    \n",
    "    # Scale the features using the pre-fitted scaler\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Original value column name\n",
    "    original_column = f'iv_{error_type}'\n",
    "    \n",
    "    # Generate predictions for each model\n",
    "    for model_name, model in models.items():\n",
    "        # Make predictions\n",
    "        predictions = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Add predictions to the dataframe\n",
    "        column_name = f'iv_{error_type}_pred_{model_name}'\n",
    "        result_df[column_name] = predictions\n",
    "        \n",
    "        # Calculate corrected value by adding the error prediction to the original value\n",
    "        result_df[f'iv_{error_type}_corrected_{model_name}'] = result_df[original_column] + predictions\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5954eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# PART 4: FEATURE IMPORTANCE ANALYSIS\n",
    "###########################################\n",
    "\n",
    "def analyze_feature_importance(model, feature_columns):\n",
    "    \"\"\"\n",
    "    Extract and display feature importance from a LightGBM model.\n",
    "    \n",
    "    Parameters:\n",
    "    model: Trained LightGBM model\n",
    "    feature_columns (list): List of feature column names\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame with feature importance scores\n",
    "    \"\"\"\n",
    "    # Get feature importance\n",
    "    importance = model.feature_importance(importance_type='split')\n",
    "    \n",
    "    # Create a DataFrame for better visualization\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_columns,\n",
    "        'Importance': importance\n",
    "    })\n",
    "    \n",
    "    # Sort by importance\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    return importance_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "762279bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bs LGB1...\n",
      "✓ Model loaded successfully\n",
      "Loading bs LGB2...\n",
      "✓ Model loaded successfully\n",
      "Loading ahbs LGB1...\n",
      "✓ Model loaded successfully\n",
      "Loading ahbs LGB2...\n",
      "✓ Model loaded successfully\n",
      "Loading cw LGB1...\n",
      "✓ Model loaded successfully\n",
      "Loading cw LGB2...\n",
      "✓ Model loaded successfully\n",
      "\n",
      "=== Model Loading Summary ===\n",
      "bs LGB1: ✓ Loaded\n",
      "bs LGB2: ✓ Loaded\n",
      "ahbs LGB1: ✓ Loaded\n",
      "ahbs LGB2: ✓ Loaded\n",
      "cw LGB1: ✓ Loaded\n",
      "cw LGB2: ✓ Loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def load_lgb_models(model_paths_dict):\n",
    "    loaded_models = {}\n",
    "\n",
    "    for error_type in model_paths_dict:\n",
    "        loaded_models[error_type] = {}\n",
    "\n",
    "        for model_name, path in model_paths_dict[error_type].items():\n",
    "            try:\n",
    "                path = path.replace('\\\\', '/')  # Normalize path\n",
    "                if not os.path.exists(path):\n",
    "                    print(f\"✗ {error_type} {model_name}: File not found at {path}\")\n",
    "                    loaded_models[error_type][model_name] = None\n",
    "                    continue\n",
    "\n",
    "                print(f\"Loading {error_type} {model_name}...\")\n",
    "                model = lgb.Booster(model_file=path)\n",
    "                print(f\"✓ Model loaded successfully\")\n",
    "\n",
    "                loaded_models[error_type][model_name] = model\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Failed to load {error_type} {model_name}: {str(e)}\")\n",
    "                loaded_models[error_type][model_name] = None\n",
    "\n",
    "    return loaded_models\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Model paths dictionary with proper path handling for Windows\n",
    "    # Use forward slashes or raw strings to avoid Unicode escape errors\n",
    "    model_paths_dict = {\n",
    "    'bs': {\n",
    "        'LGB1': r\"C:/Users/maxva/OneDrive - Tilburg University/Msc. Data Science/Master Thesis/Code/Models/LigthGBM Forecast/Firm Characteristics/LGB1_bs_model.txt\",\n",
    "        'LGB2': r\"C:/Users/maxva/OneDrive - Tilburg University/Msc. Data Science/Master Thesis/Code/Models/LigthGBM Forecast/Firm Characteristics/LGB2_bs_model.txt\"\n",
    "    },\n",
    "    'ahbs': {\n",
    "        'LGB1': r\"C:/Users/maxva/OneDrive - Tilburg University/Msc. Data Science/Master Thesis/Code/Models/LigthGBM Forecast/Firm Characteristics/LGB1_ahbs_model.txt\",\n",
    "        'LGB2': r\"C:/Users/maxva/OneDrive - Tilburg University/Msc. Data Science/Master Thesis/Code/Models/LigthGBM Forecast/Firm Characteristics/LGB2_ahbs_model.txt\"\n",
    "    },\n",
    "    'cw': {\n",
    "        'LGB1': r\"C:/Users/maxva/OneDrive - Tilburg University/Msc. Data Science/Master Thesis/Code/Models/LigthGBM Forecast/Firm Characteristics/LGB1_cw_model.txt\",\n",
    "        'LGB2': r\"C:/Users/maxva/OneDrive - Tilburg University/Msc. Data Science/Master Thesis/Code/Models/LigthGBM Forecast/Firm Characteristics/LGB2_cw_model.txt\"\n",
    "    }\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Load all models\n",
    "    loaded_models = load_lgb_models(model_paths_dict)\n",
    "    \n",
    "    # Print summary of loaded models\n",
    "    print(\"\\n=== Model Loading Summary ===\")\n",
    "    for error_type in loaded_models:\n",
    "        for model_name in loaded_models[error_type]:\n",
    "            status = \"✓ Loaded\" if loaded_models[error_type][model_name] is not None else \"✗ Failed\"\n",
    "            print(f\"{error_type} {model_name}: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43a794ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Predicting corrections for BS --\n",
      "        impl_volatility     iv_bs  iv_bs_pred_LGB1  iv_bs_corrected_LGB1  \\\n",
      "990379         0.333655  0.466571        -0.109720              0.356850   \n",
      "990380         0.328039  0.466571        -0.119451              0.347120   \n",
      "990381         0.320756  0.466571        -0.127325              0.339246   \n",
      "\n",
      "        iv_bs_pred_LGB2  iv_bs_corrected_LGB2  \n",
      "990379        -0.112547              0.354023  \n",
      "990380        -0.116486              0.350085  \n",
      "990381        -0.119476              0.347094  \n",
      "\n",
      "-- Predicting corrections for AHBS --\n",
      "        impl_volatility   iv_ahbs  iv_ahbs_pred_LGB1  iv_ahbs_corrected_LGB1  \\\n",
      "990379         0.333655  0.466143          -0.100951                0.365192   \n",
      "990380         0.328039  0.463298          -0.104567                0.358731   \n",
      "990381         0.320756  0.460615          -0.105047                0.355569   \n",
      "\n",
      "        iv_ahbs_pred_LGB2  iv_ahbs_corrected_LGB2  \n",
      "990379          -0.093235                0.372908  \n",
      "990380          -0.095074                0.368224  \n",
      "990381          -0.096061                0.364554  \n",
      "\n",
      "-- Predicting corrections for CW --\n",
      "        impl_volatility     iv_cw  iv_cw_pred_LGB1  iv_cw_corrected_LGB1  \\\n",
      "990379         0.333655  0.450584        -0.078871              0.371713   \n",
      "990380         0.328039  0.447356        -0.082069              0.365287   \n",
      "990381         0.320756  0.444564        -0.084333              0.360232   \n",
      "\n",
      "        iv_cw_pred_LGB2  iv_cw_corrected_LGB2  \n",
      "990379        -0.068479              0.382105  \n",
      "990380        -0.071215              0.376141  \n",
      "990381        -0.074707              0.369857  \n",
      "\n",
      "✓ option_only_data[21] updated.\n"
     ]
    }
   ],
   "source": [
    "test_data_per_horizon = {}\n",
    "import joblib\n",
    "\n",
    "# Define the scaler path\n",
    "scaler_path = r\"C:\\Users\\maxva\\OneDrive - Tilburg University\\Msc. Data Science\\Master Thesis\\Code\\Models\\LigthGBM Forecast\\Firm Characteristics\\scaler.pkl\"\n",
    "scaler = joblib.load(scaler_path)\n",
    "\n",
    "\n",
    "\n",
    "# 1) Copy base test set\n",
    "base_df = test_data[1].copy()\n",
    "\n",
    "# 2) Define features (remove target + metadata columns)\n",
    "exclude_cols = [\n",
    "    'iv_bs_error','iv_ahbs','iv_ahbs_error','iv_bs','iv_cw','iv_cw_error',\n",
    "    'impl_volatility','moneyness_category','ID','date','new_id',\n",
    "    'open_interest','option_price','prediction_horizon',\n",
    "    'test_date','train_date','volume', 'iv_ahbs_corrected_LGB1', 'iv_ahbs_corrected_LGB2', 'iv_ahbs_pred_LGB1', 'iv_ahbs_pred_LGB2',\n",
    "    'iv_bs_corrected_LGB1', 'iv_bs_corrected_LGB2',\n",
    "    'iv_bs_pred_LGB1', 'iv_bs_pred_LGB2', 'iv_cw_corrected_LGB1', 'iv_cw_corrected_LGB2', 'iv_cw_pred_LGB1', 'iv_cw_pred_LGB2'\n",
    "]\n",
    "feature_columns = [c for c in base_df.columns if c not in exclude_cols]\n",
    "\n",
    "# 3) Add model predictions and corrections\n",
    "df = base_df.copy()\n",
    "for error_type in ['bs', 'ahbs', 'cw']:\n",
    "    print(f\"\\n-- Predicting corrections for {error_type.upper()} --\")\n",
    "    \n",
    "    models_for_type = loaded_models[error_type]  # {'LGB1': model_obj, 'NN4': model_obj}\n",
    "    \n",
    "    # This helper must add pred/corrected cols in-place\n",
    "    df = predict_and_add_to_test_data(\n",
    "        models=models_for_type,\n",
    "        test_data=df,\n",
    "        scaler=scaler,\n",
    "        feature_columns=feature_columns,\n",
    "        error_type=error_type\n",
    "    )\n",
    "    \n",
    "    # Preview new prediction columns\n",
    "    cols = ['impl_volatility', f'iv_{error_type}']\n",
    "    for model in ['LGB1', 'LGB2']:\n",
    "        cols += [f'iv_{error_type}_pred_{model}', f'iv_{error_type}_corrected_{model}']\n",
    "    print(df[cols].head(3))\n",
    "\n",
    "# 4) Store final result for this horizon\n",
    "test_data[horizon] = df.copy()\n",
    "print(f\"\\n✓ option_only_data[{horizon}] updated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e606af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_data_horizon_1_for_graph.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "922ff19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_extended_model_comparisons(df):\n",
    "    models = {\n",
    "        'BS': ('iv_bs', 'iv_bs_corrected_NN3', 'iv_bs_corrected_LGB1'),\n",
    "        'AHBS': ('iv_ahbs', 'iv_ahbs_corrected_NN3', 'iv_ahbs_corrected_LGB1'),\n",
    "        'Carr and Wu': ('iv_cw', 'iv_cw_corrected_NN3', 'iv_cw_corrected_LGB1')\n",
    "    }\n",
    "\n",
    "    fig, axs = plt.subplots(3, len(models), figsize=(5 * len(models), 12))\n",
    "\n",
    "    for idx, (model_name, (base_col, nn3_col, lgb1_col)) in enumerate(models.items()):\n",
    "        # Top row: Base model vs Market\n",
    "        axs[0, idx].scatter(df['moneyness'], df['impl_volatility'], color='blue', label='Market IV', s=10, alpha=0.6)\n",
    "        axs[0, idx].scatter(df['moneyness'], df[base_col], color='orange', label=f'{model_name} IV', s=10, alpha=0.6)\n",
    "        axs[0, idx].set_title(f'{model_name}')\n",
    "        axs[0, idx].set_xlabel('Moneyness')\n",
    "        axs[0, idx].set_ylabel('Implied Volatility')\n",
    "        axs[0, idx].legend()\n",
    "\n",
    "        # Middle row: NN3 Corrected model vs Market\n",
    "        axs[1, idx].scatter(df['moneyness'], df['impl_volatility'], color='blue', label='Market IV', s=10, alpha=0.6)\n",
    "        axs[1, idx].scatter(df['moneyness'], df[nn3_col], color='orange', label=f'{model_name} + NN3', s=10, alpha=0.6)\n",
    "        axs[1, idx].set_title(f'{model_name} + NN3')\n",
    "        axs[1, idx].set_xlabel('Moneyness')\n",
    "        axs[1, idx].set_ylabel('Implied Volatility')\n",
    "        axs[1, idx].legend()\n",
    "\n",
    "        # Bottom row: LGB1 Corre\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
